[
  {
    "objectID": "logit_results.html",
    "href": "logit_results.html",
    "title": "Regresión logística en R",
    "section": "",
    "text": "La siguiente guía produce todos los pasos empleando R para abrir los datos, preparar los datos, ajustar modelos de regresión logística, y describir los resultados encontrados.\nEste documento incluye diferentes secciones donde se ilustran los diferentes pasos que se pueden emplear para producir los resultados.\nPara dirigirse específicamente a la descripción de resultados, hacer click aqui."
  },
  {
    "objectID": "logit_results.html#likelihood-ratio-test-lrt",
    "href": "logit_results.html#likelihood-ratio-test-lrt",
    "title": "Regresión logística en R",
    "section": "Likelihood Ratio Test (LRT)",
    "text": "Likelihood Ratio Test (LRT)\nLa formula de Likelihood ratio es:\n\\(\\chi^2_{diff} = -2(LL_{0} - LL{1})\\)\nDonde,\n\n\n\\(LL_{1}\\) = es la loglikelihood del modelo de interés\n\n\\(LL_{0}\\) = es la loglikelihood del modelo nulo\n\n\\(\\chi^2_{diff}\\) = es un valor de \\(\\chi^2\\).\n\nLo que nos entrega esta prueba, es una medida global de discrepancia entre la devianza del modelo nulo, en contraste al modelo de interés. Cuando esta diferencia es muy pequeña, condicional a los grado de libertad, afirmamos que el modelo de interés produce devianzas muy similares a las del modelo que solo contiene al porcentaje de la variable de interés (i.e., el análago del promedio de la regresión lineal). En cambio, cuando esta discrepancia es superior a lo esperado en la distribución de \\(\\chi^2\\), entonces afirmamos que el modelo ajusta de mejor manera a los datos.\nPara obtener este indicador, podemos aplicar el siguiente código.\nCódigo 4.1. Likelihood ratio test\n\n# Likelihood ratio test\nanova(m00, m04, test=\"LRT\")  \n\nAnalysis of Deviance Table\n\nModel 1: drop ~ 1\nModel 2: drop ~ 1 + zach + zses + int\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1     16609     9967.2                          \n2     16606     8045.5  3   1921.7 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nImportante\n\n\n\nLas pruebas de Likelihood ratio test son muy importantes, porque son aplicables a cualquier modelo estadístico basado en maxima verosimilitud (i.e., maximum likelihood). Estas pueden ser aplicadas sobre diferentes modelos tales como: regresion lineal, modelos multinivel, modelos de regresion logística, modelos generalizados, confirmatory factor analysis, modelos de respuesta al item, entre otros modelos estimados con maximum likelihood."
  },
  {
    "objectID": "logit_results.html#mcfadden-r2",
    "href": "logit_results.html#mcfadden-r2",
    "title": "Regresión logística en R",
    "section": "McFadden \\(R^2\\)\n",
    "text": "McFadden \\(R^2\\)\n\nLa formula para McFadden R^2, es la siguiente:\n\\(\\text{McFadden } R^2 = 1 - \\frac{LL_{1}}{LL_{0}}\\)\nDonde,\n\n\n\\(LL_{1}\\) = es la loglikelihood del modelo de interés\n\n\\(LL_{0}\\) = es la loglikelihood del modelo nulo\n\nEn esta fórmula se comparamos la máxima verosimilitud no atrribuible al modelo, con la máxima verosimilitud del modelo nulo. En otras palabras, estamos comparando que proporción de máxima verosimilitud es capaz de explicar el modelo que hemos ajustado, en contraste a toda la máxima verosimilitud que puede explicar solo el “promedio” o porcentaje de respuesta sobre los datos observados.\nEste indicador, no es precisamente una medida de proporción de varianza explicada, pero se comporta de igual manera. Lo anterior, en el sentido de que a medida que se acerca 1, implica un modelo que ajusta bien a los datos; y a medida que se aleja de 1, implica un modelo que predice a los datos observados en menor medida.\nPara obtener el McFadden R^2, vamos a emplear un método manual, y otro empleando a la librería perfomance (Lüdecke, et al., 2021).\nCódigo 4.2. McFadden R^2\n\n# McFadden R2 via computación manual\nll_0 &lt;- as.numeric(logLik(m00))\nll_1 &lt;- as.numeric(logLik(m04))\n\nMcFadden_r2 &lt;- 1 - ll_1/ll_0\nMcFadden_r2\n\n[1] 0.1928037\n\n# McFadden via library(performance)\nperformance::r2_mcfadden(m04)\n\n# R2 for Generalized Linear Regression\n       R2: 0.193\n  adj. R2: 0.193"
  },
  {
    "objectID": "logit_results.html#horowitz-r2",
    "href": "logit_results.html#horowitz-r2",
    "title": "Regresión logística en R",
    "section": "Horowitz \\(R^2\\)\n",
    "text": "Horowitz \\(R^2\\)\n\nLa formula para Horowitz R^2, es la siguiente:\n\\(\\text{Horowitz } R^2 = 1 - \\frac{LL_{1}-\\frac{m}{2}}{LL_{0}}\\)\nDonde,\n\n\n\\(LL_{1}\\) = es la loglikelihood del modelo de interés\n\n\\(LL_{0}\\) = es la loglikelihood del modelo nulo\n\n\\(m\\) = número de parámetros del modelo, excluyendo al intercepto\n\nCódigo 4.3. Horowitz R^2\n\n# horowitz_r2 R2 via computación manual\nll_0 &lt;- as.numeric(logLik(m00))\nll_1 &lt;- as.numeric(logLik(m04))\n\n\nm &lt;- broom::tidy(m04) %&gt;%\n     dplyr::filter(term != '(Intercept)') %&gt;%\n     nrow()\n\nhorowitz_r2 &lt;- 1 - (ll_1-(m/2))/ll_0\nhorowitz_r2\n\n[1] 0.1925027\n\n\nEste indicador ajuste, puede ser visto como un McFadden \\(R^2\\) corregido por la cantidad de parámetros que posee el modelo ajustado. En estudios de simulaciones, este indicador es menos sensible al tamaño de la muestra, la cantidad de covariables del modelo, y de la cantidad de categorias presentes en la variable de respuesta (i.e., en modelos de más de dos categorías) (Hemmert et al., 2018). Por esta última razón, se lo considera un indicador más ventajoso en contraste a otros indicadores de pseudo \\(R^2\\) para diferentes modelos logit."
  },
  {
    "objectID": "logit_results.html#efrons-r2",
    "href": "logit_results.html#efrons-r2",
    "title": "Regresión logística en R",
    "section": "Efron’s \\(R^2\\)\n",
    "text": "Efron’s \\(R^2\\)\n\nEn contraste, Efron’s R^2 sigue la racionalidad del R^2 de la regresión lineal. La formula de este indicador, es la siguiente:\n\\(\\text{Efron's } R^2 = 1 - \\frac{\\sum{(y_{i}-\\pi_{i})^2}}{\\sum{(y_{i}-\\hat{y})^2}}\\)\nDonde,\n\n\n\\(y_{i}\\) = es el valor observado \\(y\\), para cada fila \\(i\\)\n\n\n\\(\\pi_{i}\\) = es el valor esperado \\(y\\), para cada fila \\(i\\), dado el modelo de interés\n\n\\(\\hat{y}\\) = es el valor esperado \\(y\\), por ejemplo \\(\\hat{y} = \\frac{\\sum{y_{i}}}{n}\\)\n\n\nCódigo 4.4. Efron’s R^2\n\n# Efron R^2 via computación manual\ny_hat &lt;- stats::predict(m04, type = \"response\")\ny &lt;- data_model$drop\npr_y &lt;- mean(y)\n\nefron_r2 &lt;- (1 - (sum((y - y_hat)^2)) / (sum((y - pr_y)^2)))\nefron_r2\n\n[1] 0.1276261\n\n# Efron R^2 via library(perfomance)\nperformance::r2_efron(m04)\n\n[1] 0.1276261"
  },
  {
    "objectID": "logit_results.html#mckelvey-zavoina-pseudo-r2",
    "href": "logit_results.html#mckelvey-zavoina-pseudo-r2",
    "title": "Regresión logística en R",
    "section": "McKelvey & Zavoina Pseudo \\(R^2\\)\n",
    "text": "McKelvey & Zavoina Pseudo \\(R^2\\)\n\nMcKelvey & Zavoina Pseudo R^2 puede ser atractivo, porque sigue la lógica de producir una proporción de varianza explicada. En esta aproximación, se asumen que podemos realizar la siguiente descomposición:\n\\[S_{T}^2 = S_{R}^2 + S_{E}^2\\]\nDonde,\n\\(S_{T}^2\\) es la suma de cuadrados totales (i.e., la varianza total). \\(S_{E}^2\\) es la suma de cuadrados generada por el modelo \\(S_{R}^2\\) es la suma de cuadrados del error\nPara el caso de los modelos de regresión logística la varianza residual de \\(y\\) es fija y se expresa con el siguiente término \\(\\pi^2/3\\).\nDe esta forma el \\(R^2\\) de McKelvey & Zavoina (1975) puede ser expresado para la regresión logística de la siguiente forma:\n\nSuma de cuadrados esperadas dado el modelo:\n\n\\(S_{E}^2 = \\sum{(\\hat{y}_{i}}-\\hat{\\bar{y}})^2\\)\n\nSuma de cuadrados residuales:\n\n\\(S_{R}^2 = n*\\pi^2/3\\)\n\nSuma de cuadrados totales:\n\n\\(S_{T}^2 = \\sum{(\\hat{y}_{i}}-\\hat{\\bar{y}})^2 + (n*\\pi^2/3)\\)\nCon los términos anteriores podemos construir el R^2 esperado:\n\\(\\hat{R^2} = \\frac{S_{E}^2}{S_{T}^2}=\\frac{\\sum{(\\hat{y}_{i}}-\\hat{\\bar{y}})^2}{\\sum{(\\hat{y}_{i}}-\\hat{\\bar{y}})^2 + (n*\\pi^2/3)}\\)\nCódigo 4.5. McKelvey & Zavoina Pseudo \\(R^2\\)\n\n# McKelvey & Zavoina Pseudo R^2 via computación manual (método 1)\n\n## términos\ny_hat &lt;- stats::predict(m04, type = \"link\")\nbar_y_hat &lt;- mean(y_hat)\nn &lt;- nrow(data_model)\nsigma_2 &lt;- pi^2/3\n\n# suma de cuadrados del modelo\nsse &lt;- sum((y_hat - bar_y_hat)^2)\n# suma de cuadrados totakes\nsst &lt;- sse + n * sigma_2\n\nmzr2_m1 &lt;- sse / sst\nmzr2_m1\n\n[1] 0.4982506\n\n# McKelvey & Zavoina Pseudo R^2 via computación manual (método 2)\n\n# formula para obetener varianza de la población (y no de la muestra)\nvar_pop &lt;- function(x){\nn &lt;- length(x)\nvar_pop &lt;- var(x) * (n - 1)/n\nreturn(var_pop)\n}\n\nvar_star_y &lt;- var_pop(y_hat)\n\nvar_star_t &lt;- var_pop(y_hat) + (pi^2)/3\n\nmzr2_m2 &lt;- var_star_y/var_star_t\nmzr2_m2\n\n[1] 0.4982506\n\n# McKelvey & Zavoina Pseudo R^2 via performance::r2_mckelvey() (método 3)\nmzr2_m3 &lt;- performance::r2_mckelvey(m04)\nmzr2_m3\n\nMcKelvey's R2 \n    0.4982506 \n\n# Comparación de métodos de calculos empleados\ndata.frame(\nmethod = c('via SSE', 'via Varianza', 'performance::r2_mckelvey'),\nMZ_R2 = c(mzr2_m1, mzr2_m2, mzr2_m3)\n) %&gt;%\nknitr::kable(., digits = 8)\n\n\n\nmethod\nMZ_R2\n\n\n\nvia SSE\n0.4982506\n\n\nvia Varianza\n0.4982506\n\n\nperformance::r2_mckelvey\n0.4982506"
  },
  {
    "objectID": "logit_results.html#indicadores-de-ajuste",
    "href": "logit_results.html#indicadores-de-ajuste",
    "title": "Regresión logística en R",
    "section": "Indicadores de ajuste",
    "text": "Indicadores de ajuste\nUna forma de obtener cada uno de estos indicadores de ajuste con una sola función es empleando a la función blorr::blr_model_fit_stats(). Además, podemos emplear la función blorr::blr_multi_model_fit_stats, con la cual podemos comparar los indicadores de ajuste de varios modelos. Finalmente, empleando a broom::glance() podemos obtener algunos de los indicadores que se producen con summary(model), pero en formato tabla, lo cual nos puede servir para extraer estadísticos particulares del modelo (e.g., loglikelihood, deviance, AIC, BIC).\nCódigo 4.6. Indicadores de ajuste\n\n# indicadores de ajuste con blorr\nblorr::blr_model_fit_stats(m04)\n\n                              Model Fit Statistics                                \n---------------------------------------------------------------------------------\nLog-Lik Intercept Only:     -4983.621    Log-Lik Full Model:            -4022.761 \nDeviance(16606):             8045.521    LR(3):                          1921.721 \n                                         Prob &gt; LR:                         0.000 \nMCFadden's R2                   0.193    McFadden's Adj R2:                 0.192 \nML (Cox-Snell) R2:              0.109    Cragg-Uhler(Nagelkerke) R2:        0.242 \nMcKelvey & Zavoina's R2:        0.498    Efron's R2:                        0.128 \nCount R2:                       0.911    Adj Count R2:                      0.001 \nBIC:                         8084.392    AIC:                            8053.521 \n---------------------------------------------------------------------------------\n\n# comparacion de modelos\nblorr::blr_multi_model_fit_stats(m00, m04)\n\n                               Measures   Model 1   Model 2\nloglik_null      Log-Lik Intercept Only -4983.621 -4983.621\nloglik_model         Log-Lik Full Model -4983.621 -4022.761\nm_deviance                     Deviance  9967.242  8045.521\nlr_ratio                             LR     0.000  1921.721\nlr_pval                       Prob &gt; LR     1.000     0.000\nmcfadden                  MCFadden's R2     0.000     0.193\nadj_mcfadden          McFadden's Adj R2     0.000     0.192\nm_aic                 ML (Cox-Snell) R2  9969.242  8053.521\ncox_snell    Cragg-Uhler(Nagelkerke) R2     0.000     0.109\nm_bic           McKelvey & Zavoina's R2  9976.960  8084.392\nmckelvey                     Efron's R2     0.000     0.498\neffron                         Count R2     0.000     0.128\nnagelkerke                 Adj Count R2     0.000     0.242\ncount_r2                            AIC     0.911     0.911\ncount_adj                           BIC     0.000     0.001\n\n# indicadores de ajuste con broom\nbroom::glance(m04)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;\n1         9967.   16609 -4023. 8054. 8084.    8046.       16606 16610"
  },
  {
    "objectID": "logit_results.html#qué-indicador-de-pseudo-r-emplear",
    "href": "logit_results.html#qué-indicador-de-pseudo-r-emplear",
    "title": "Regresión logística en R",
    "section": "¿Qué indicador de Pseudo R emplear?",
    "text": "¿Qué indicador de Pseudo R emplear?\nSi comparamos los diferentes indicadores de pseudo \\(R^2\\) empleados en regresión logística podemos ver que estos difieren en tamaño de manera importante (ver tabla siguiente.\n\nCódigo para obtener cada uno de los pseudo R^2data.frame(\npseudo_r2 = c('Effron', 'McFadden', 'Horowitz', 'McKelvey & Zavoina'),\nestimate = c( \nas.numeric(performance::r2_efron(m04)),\nas.numeric(performance::r2_mcfadden(m04)$R2),\nhorowitz_r2,\nas.numeric(performance::r2_mckelvey(m04))),\nracionalidad = c(\n'Reducción de predichos',\n'Reducción de devianza',\n'Reducción de devianza, corregido por la cantidad de parámetros',\n'Reducción de varianza latente'\n)) %&gt;%\narrange(estimate) %&gt;%\nknitr::kable(., digits = 2, caption = 'Tabla 1: comparación de R^2 para modelo `m04`')\n\n\nTabla 1: comparación de R^2 para modelo m04\n\n\n\n\n\n\n\npseudo_r2\nestimate\nracionalidad\n\n\n\nEffron\n0.13\nReducción de predichos\n\n\nHorowitz\n0.19\nReducción de devianza, corregido por la cantidad de parámetros\n\n\nMcFadden\n0.19\nReducción de devianza\n\n\nMcKelvey & Zavoina\n0.50\nReducción de varianza latente\n\n\n\n\n\nNo existe un consenso transversal en la literatura, respecto a cual indicador \\(R^2\\) es más adecuado (O’Connel et al, 2019). No obstante, Menard (2000) plantea que McFadden \\(R^2\\) puede ser preferible por dos razones: a) este es un indicador que puede ser interpretado como una medida de reducción de error, y b) que este indicador es insensible a la tasa de prevalencia del evento de interés, es decir el \\(Pr(y = 1)\\). Por su parte Hemmert et al. (2018), recomienda al indicador de pseudo de R^2 de Horowitz (1982), debido a que este indicador es menos sensible al tamaño muestral, y la distribución de categorias de la variable de respuesta.\nNo obstante, si el uso de estos indicadores, es solo comparación entre modelos ajustados sobre los mismos datos, y sobre la misma variable dependiente, cualquiera de estos indicadores debiera al propósito de ayudar a la selección de modelos.\nO’Connel et al. (2019) por su parte, plantea que el indicador McFadden \\(R^2\\) es uno de los indicadores más intuitivos como medida de mejora de ajuste, dado el modelo de interés.\nDe todas formas, lo más importante a tener en cuenta, es el propósito para el cual se quiera emplear uno de estos indicadores, e indicar claramente cual es el indicador que esta siendo empleado en el reporte de resultados del manuscrito (Menard, 2000; Hemmert et al., 2018). En otras palabras, la recomendación a seguir es siempre reportar el ajuste del modelo, indicando explícitamente cuál de estos indicadores es el reportado.\n\n\n\n\n\n\nTip\n\n\n\nEn el reporte de resultado de regresión logística, en el primer párrafo de descripción de resultados sobre el ajuste de modelo, se requiere indicar claramente el indicador de pseudo \\(R^2\\) que esta siendo reportado."
  },
  {
    "objectID": "logit_results.html#calidad-de-la-clasificación",
    "href": "logit_results.html#calidad-de-la-clasificación",
    "title": "Regresión logística en R",
    "section": "Calidad de la clasificación",
    "text": "Calidad de la clasificación\nUno de los indicadores más sencillos de calidad de clasificación es la proporción de casos predichos en contraste a la cantidad de observaciones. Este indicador puede ser obtenido de variadas maneras. La forma más sencilla, consiste en producir una tabla de contingencia entre los valores predichos, y los valores observados. Se suman los valores correctamente predichos de cada categoria, y se dividen por la cantidad de observaciones.\nCoincide, que para el caso de regresión logistica, este es el mismo indicador de cantidad de clasificaciones correctas o Count \\(R^2\\).\nOtro indicador de clasificación, es el indicador \\(tau_{p}\\) Menard (2000, 2001). Este es un indicador, basado en clasificaciones basadas en probabilidades no simétricas (Ma & Redmond, 1995). Este indicador consiste en la proporción de clasificaciones correctas ajustando por las probabilidades a priori. Es decir, la tasa de prevalencia del evento, previo a que tengamos información de las covariables. Este segundo término se obtiene como las probabilidades marginales de la distribución de referencia (i.e., el porcentaje del evento de interes, obtenido desde la variable e respuesta). En la literatura de clasificación este indicador tambien se lo conoce como Klecka’s \\(\\tau\\) (Klecka, 1980). De forma análoga, tambien es posible producir \\(\\tau_{e}\\), el cual ajusta las clasificaciones empleando una clasificación al azar. La cual, en el caso del modelo de regresión logística es equivalente a .5 (1/cantidad de valores posibles).\nA continuación, incluimos código para producir a los indicadores de:\n\ncount \\(R^2\\) = Porcentaje de clasificacion correcta count_r2\n\nAccuracy = Porcentaje de clasificacion correcta, sobre el total accuracy\n\n\n\\(\\tau_{p}\\) = Porcentaje de classifiación correcta, ajustado por la prevalencia (\\(\\tau_{p}\\))\n\n\\(\\tau_{e}\\) = Porcentaje de classifiación correcta, ajustado por azar (\\(\\tau_{e}\\))\n\n\\(\\lambda_{p}\\) Porcentaje de classifiación correcta, ajustado por categoria modal (\\(\\lambda_{p}\\))\n\n\n\n\n\n\n\nImportante\n\n\n\nEs importante señalar que los indicadores de clasificación no son calculados por defecto por diferentes paquetes estadísticos. Y por tanto, hay menos acuerdo en la literatura respecto a cual de estos indicadores es más adecuado reportar (O’Connel et al, 2019). Menard (2000) recomienda al indicador de \\(\\tau_{p}\\), y al count \\(R^2\\) o porcentaje de clasificación correctas por sobre el total. En esta guia, emplearemos este indicador para crear el reporte de resultados.\n\n\nCódigo 4.7. Indicadores de clasificación\n\n# count pseudo R2\nblorr::blr_model_fit_stats(m04)$count_r2\n\n[1] 0.9111379\n\n# accuracy\nblorr::blr_confusion_matrix(m04)$accuracy\n\n[1] 0.9111379\n\n# calculos manuales\ny_obs &lt;- m04$y\ny_hat &lt;- dplyr::if_else(predict(m04, type = \"response\") &gt;= 0.5, 1, 0)\nn_obs &lt;- length(y_obs)\n\nf_ii &lt;- dplyr::if_else(y_obs == y_hat,1,0)\n\n## count pseudo R2\ncount_r2 &lt;- sum(f_ii)/n_obs\ncount_r2\n\n[1] 0.9111379\n\n## tau_e Ma & Redmond (1995)\np_o  &lt;- sum(f_ii)/n_obs\np_re &lt;- 0.5\n# Note: clasification by chance\n\ntau_e &lt;- (p_o - p_re)/(1-p_re)\ntau_e\n\n[1] 0.8222757\n\n## tau p Ma & Redmond (1995)\np_o  &lt;- sum(f_ii)/n_obs\np_rp &lt;- mean(y_obs) \n# Note: marginal distribution of the reference data\n\ntau_p &lt;- (p_o - p_rp)/(1-p_rp)\ntau_p\n\n[1] 0.9024648\n\n## tau p Klecka's (1980)\nn_p &lt;- sum(y_obs)\nn_q &lt;- n_obs - sum(y_obs)\n\ntau_num  &lt;- sum(f_ii) - pr_y*(n_p + n_q)\ntau_den &lt;- n_obs - pr_y*(n_p + n_q)\ntau_p &lt;- tau_num/tau_den\ntau_p\n\n[1] 0.9024648\n\n## tau_p Menard (2001)\nerrors_without_model &lt;- 1 - p_rp\nerrors_with_model &lt;- 1-p_o\n\ntau_p &lt;- (errors_without_model - errors_with_model)/errors_without_model\ntau_p\n\n[1] 0.9024648\n\n## lambda p (Menard, 2000)\nn_mode &lt;- sum(y_obs)\nlambda_num  &lt;- n_obs - sum(f_ii)\nlambda_den  &lt;- n_obs - n_mode\nlambda_p &lt;- 1 - lambda_num/lambda_den\nlambda_p\n\n[1] 0.9024648"
  },
  {
    "objectID": "logit_results.html#introducción-1",
    "href": "logit_results.html#introducción-1",
    "title": "Regresión logística en R",
    "section": "Introducción",
    "text": "Introducción\n\nEl dropout escolar es un problema reconocido en términos de política pública para los paises. Es uno de los riesgo negativos más grandes en salud pública (Freudenberg et al., 2007), así como un conocido factor detrimental para la empleabilidad futura de las persoas (Solga, 2002). Este fenómeno interrumpe el proceso educativo del cual participan los estudiantes, y mientras más temprano ocurra, mayores son las consecuenci\nLos indicadores de riesgo con mayor cobertura en el estudio de dropout escolar, es el desempeño académico de los estudiantes, y el nivel socioeconómico de las familias de los estudiantes. Sin embargo, una pregunta que posee menor cobertura en la literatura son los posibles efectos de interacción de estos factores. Esta pregunta es común que no sea abordada en estudios previos, debido a la falta de poder estadístico (e.g., Sommet, 2023). Mientras la evaluación de relaciones entre variables requiere de muestras de unos 100 casos, para la adecuada evaluación relaciones condicionales se puede requerir de muestras de hasta 16 veces el tamaño anterior (Gellman, 2008).\nEl presente estudio se sirve de una muestra de datos nacional de gran tamaño (n = 16610) para estudiar el rol del nivel socioeconómico de los estudiantes sobre el dropout escolar. En particular, queremos saber si este factor es un factor de riesgo para todos los estudiantes, y/o si es un factor de riesgo que posee mayores consecuencias para estudiantes de menor desempeño académico."
  },
  {
    "objectID": "logit_results.html#método",
    "href": "logit_results.html#método",
    "title": "Regresión logística en R",
    "section": "Método",
    "text": "Método\n\n[aqui iría la descripción de la muestra, las variables empleadas, y el tipo de modelo de estadístico empleado para producir los resultados empleados en la argumentación del artículo]."
  },
  {
    "objectID": "logit_results.html#texto_resultados",
    "href": "logit_results.html#texto_resultados",
    "title": "Regresión logística en R",
    "section": "Resultados",
    "text": "Resultados\nAjuste global. El modelo final, en contraste al modelo nulo presenta un mejor ajuste (LRT(3) = 1921.72, p &lt; .001). Este modelo reduce el error del modelo nulo en cerca de 19% (McFadden Adj \\(R^2\\) = 0.19). El modelo clasifica de forma adecuada a 91% de las observaciones (count \\(R^2\\) = .01). Con estos resultados concluimos, que en forma global, el desempeño académico de los estudiantes en octavo grado, y los antecedentes socioeconómicos de las familias, son relevantes para entender la tasa de deserción escolar de los estudiantes secundarios.\nResultados. En terminos generales, se observa que entre los estudiantes incluidos en el estudios, se observa una tasa de deserción escolar de 8.89%.\nCon los resultados obtenidos del modelo ajustado podemos indicar que los estudiantes con mayores logros académicos al inicio de la ventana de observación presentan menores chances de interrumpir su trayectoria escolar (b = -3.17 (0.05), p &lt; .001, OR = .31). En términos relativos, esto indica que los estudiantes con 1 desviación estandar mayor de desempeño académico, tienen 3 veces más chances de concluir sus estudios de secundaria, que el resto de sus pares (1/OR = 3.23).\nPor su parte, el nivel socioeconómico de las familias de los estudiantes tambien presenta una relación negativa con la deserción escolar (b = -1.17 (0.05), p &lt; .001, OR = .42; 1/OR = 2.36). Estudiantes de familias con mayor nivel socioeconómico presentan mayores chances de completar sus estudios escolares. En terminos relativos, estudiantes a una desviación estándar de mayor nivel socioeconómico, presentan más del doble de chances de completar sus estudios escolares (1/OR = 2.36).\n\nCódigo que genera a la Tabla 1 de resultados# metodo 4: broom::tidy() y edición de campus\n\n## función para decinir 2 decimales\ndecimales &lt;- function (x, k) {\n    format(round(x, k), nsmall = k)\n}\n\n\n## tabla con estimados\ntabla_1 &lt;- broom::tidy(m04) %&gt;%\nmutate(text = case_when(\nterm == '(Intercept)' ~ 'intercepto',\nterm == 'zach'        ~ 'logro académico (puntaje z)',\nterm == 'zses'        ~ 'nivel socioeconómico (puntaje z)',\nterm == 'int'         ~ 'interacción'\n)) %&gt;%\nmutate(e  = decimales(estimate, 2)) %&gt;%\nmutate(se = paste0('(', decimales(std.error, 2), ')')) %&gt;%\nmutate(star = case_when(\np.value &lt;  .001 ~ '***',\np.value &lt;  .01  ~ '** ',\np.value &lt;  .05  ~ '*  ',\np.value &gt;= .05  ~ '   '\n)) %&gt;%\nmutate(odds_ratio = decimales(exp(estimate),2))  %&gt;%\nmutate(reverse_odds_ratio = decimales(1/exp(estimate),2))  %&gt;%\nmutate(odds_ratio = case_when(\ntext == 'intercepto' ~ '',\ntext != 'intercepto' ~ odds_ratio\n)) %&gt;%\nmutate(reverse_odds_ratio = case_when(\ntext == 'intercepto' ~ '',\ntext != 'intercepto' ~ reverse_odds_ratio\n)) %&gt;%\ndplyr::select(text, e, se, star, odds_ratio, reverse_odds_ratio)\n\ntabla_1 %&gt;%\nknitr::kable(., digits = 2, caption = 'Tabla 1: resultados de regresión logística sobre el evento de deserción escolar')    \n\n\nTabla 1: resultados de regresión logística sobre el evento de deserción escolar\n\n\n\n\n\n\n\n\n\ntext\ne\nse\nstar\nodds_ratio\nreverse_odds_ratio\n\n\n\nintercepto\n-3.17\n(0.05)\n***\n\n\n\n\nlogro académico (puntaje z)\n-1.17\n(0.05)\n***\n0.31\n3.24\n\n\nnivel socioeconómico (puntaje z)\n-0.86\n(0.05)\n***\n0.42\n2.36\n\n\ninteracción\n-0.21\n(0.05)\n***\n0.81\n1.23\n\n\n\n\n\nFinalmente, observamos que estos dos factores, desempeño académico en 8vo grado, y nivel socioeconómico de las familias, son factores que interactúan entre sí (b = -0.21 (0.05), p &lt; .001). Para ilustrar la dirección de estos resultados, vamos a producir probabilidades condicionales a -2 y 2 desviaciones estándar por sobre el promedio para desempeño académico, y nivel socioeconómico de las familias, e ilustraremos estos resultados con la Figura 1.\n\nCódigo que genera a la Figura 1 para ilustrar la Interacción# valores de interés\nlo_ach &lt;- -2\nhi_ach &lt;-  2\nlo_ses &lt;- -2\nhi_ses &lt;-  2\n\n# coeficientes en logits del modelo\nb0 &lt;- -3.174\nb1 &lt;- -1.174\nb2 &lt;- -0.857\nb3 &lt;- -0.209\n\n# logits esperados a cada conjunto de valores de interés\ne_logit_1 &lt;- b0 + b1*(lo_ach) + b2*(lo_ses) + b3*(lo_ach*lo_ses)\ne_logit_2 &lt;- b0 + b1*(lo_ach) + b2*(hi_ses) + b3*(lo_ach*hi_ses)\ne_logit_3 &lt;- b0 + b1*(hi_ach) + b2*(lo_ses) + b3*(hi_ach*lo_ses)\ne_logit_4 &lt;- b0 + b1*(hi_ach) + b2*(hi_ses) + b3*(hi_ach*hi_ses)\n\n\n# creamos tabla básica con los logits esperados\ndata_plot &lt;- data.frame(     \nx_var = c('Bajo NSE (-2 DS)',\n          'Alto NSE (+2 DS)',\n          'Bajo NSE (-2 DS)',\n          'Alto NSE (+2 DS)'),       \ny_var = c(e_logit_1, e_logit_2, e_logit_3, e_logit_4),\ngroup = c('Bajo Logro Académico (-2 SD)', \n          'Bajo Logro Académico (-2 SD)', \n          'Alto Logro Académico (+2 SD)',\n          'Alto Logro Académico (+2 SD)')\n)                                                     \n\n# reordenamos a los valores del factor ses\ndata_plot_figure_1 &lt;- data_plot %&gt;%                           \nmutate(ses_grp = as.factor(x_var)) %&gt;%                        \nmutate(ses_grp =                                              \n  forcats::fct_relevel(ses_grp,\n    c('Bajo NSE (-2 DS)', 'Alto NSE (+2 DS)')\n    )) %&gt;%                                                    \nmutate(ach_grp = as.factor(group)) %&gt;%                        \nmutate(ach_grp =                                              \n  forcats::fct_relevel(ach_grp,\n    c('Bajo Logro Académico (-2 SD)', \n      'Alto Logro Académico (+2 SD)')\n    )) %&gt;%\nmutate(expected_prob = 1/(1+(exp(-y_var))))                   \n\n# creamos la figura 1\nlibrary(ggplot2)\nfigure_1 &lt;- ggplot(data_plot_figure_1,  \n  aes(                                  \n    x = ses_grp,                        \n    y = expected_prob,                  \n    group = ach_grp,                    \n    color = ach_grp,                    \n    shape = ach_grp                     \n    )) +                                \ngeom_line() +                           \ngeom_point(size=4) +                    \nscale_color_manual(                     \n  values = c(                           \n    'Alto Logro Académico (+2 SD)' = 'red',                 \n    'Bajo Logro Académico (-2 SD)' = 'black'                 \n    )) +                                \nscale_shape_manual(                     \n  values = c(                           \n    'Alto Logro Académico (+2 SD)' = 19,                    \n    'Bajo Logro Académico (-2 SD)' = 15                      \n    )) +                                \nxlab('Nivel socioeconómico de las familias (puntaje z)') + \nscale_y_continuous(                     \n  name = 'Probabilidad de deserción escolar', \n  breaks = seq(0,1,.1),                 \n  limits = c(0,.6)                      \n  ) +                                    \ntheme_bw() +                             \ntheme(                                   \n  legend.title = element_blank(),        \n  panel.grid.major.x = element_blank(),  \n  panel.grid.minor.y = element_blank(),  \n  panel.grid.major.y =                              \n  element_line(linewidth = .25, colour = \"grey70\")  \n  ) +\nggtitle(\n  'Figura 1: Probabilidades de deserción escolar condicionales a valores ± 2 DS para NSE y Logro académico')                                                 \n\n\nfigure_1\n\n\n\n\n\n\n\nA medida que aumentan los valores de nivel socioeconómico de las familias, la distancia de las probabilidades condicionales de deserción escolar, disminuyen entre los estudiantes de bajo y alto desempeño escolar. Finalmente, el nivel socioeconómico de las familias acelera la relación que observamos del desempeño académico a la deserción escolar. De tal forma que los estudiantes de familias de menor nivel socieconómico, presentan mayores chances de deserción escolar, escolar entre los estuddiantes de menores niveles de logro académico, en contraste a sus pares que presentan mayor logro académico.\n\n\n\n\n\n\nNota\n\n\n\nEn el siguiente link, se puede bajar la tabla de resultados generadas en excel, y también en editada en un formato tipo APA."
  },
  {
    "objectID": "logit_results.html#anexo-1-colinealidad",
    "href": "logit_results.html#anexo-1-colinealidad",
    "title": "Regresión logística en R",
    "section": "Anexo 1: Colinealidad",
    "text": "Anexo 1: Colinealidad\nLa librería blorr provee de una función directa para diagnosticas la posible colinealidad de las covariables. En general, se esperan valores menores a 4 en el indicador VIF (i.e., variance inflation factor). Para mayores detalles de como VIF puede afectar a los errores de un modelo ver la siguiente nota en stackexchange.\n\nblorr::blr_vif_tol(m04)\n\n  Variable Tolerance      VIF\n1     zach 0.7296288 1.370560\n2     zses 0.7447871 1.342666\n3      int 0.9761323 1.024451"
  },
  {
    "objectID": "logit_results.html#anexo-2-residuales",
    "href": "logit_results.html#anexo-2-residuales",
    "title": "Regresión logística en R",
    "section": "Anexo 2: Residuales",
    "text": "Anexo 2: Residuales\nExisten diferentes tipos de residuales en el caso de la regresión logistica (ver Dunn, et al. (2018), p299). Uno de los más intuitivos son los residuales basados en devianzas, que se encuentran unit deviance, y son los que produce por defecto el paquete base de R (i.e., residual(model)), para el caso de modelo de regresion logística.\n\n# residuales basados en devianza\nblorr::blr_plot_deviance_residual(m04)\n\n\n\n\n\n\n\nDe forma muy intuitiva, se pueden hacer dos cosas con los residuales. Lo primero es que es más conveniente que estos se distribuyan de forma similar a entre las observaciones. De caso contrario, uno puede sospechar que el modelo ajusta de mejor manera para algunas observaciones, en contraste a otras.\nHarrel (2015) es de la opinión que el diagnóstico general de lo residuales de los modelos de regresión logística es menos util, que en el caso de la regresión lineal. Lo anterior, porque el modelo no posee una distribución esperada para los residuales (e.g., por ejemplo una distrivución normal). En terminos más generales la regresión logística no posee un modelo para los errores, como en el caso de la regresión lineal.\nPor su parte Dunn et al. (2018, p228) muestra los residuales de la unidad de devianza (i.e., unit deviance), que es la escala que en se encuentran los residuales que produce por defecto, poseen una distribución cercana \\(\\chi^2\\). Y estos valores debieran ser cercanos a 1; sin embargo si la prevancia de \\(Pr(y=1)\\) es muy alta o muy baja (menor a .1, o mayor .9), las devianzas esperadas se empinan y pueden ser mayores a 1.\nEn el modelo ajustado, esto es precisamete lo que sucede, ya que estamos modelando una variable de respuesta donde se observa \\(Pr(y=1) = .09\\). En este caso observamos varios casos son residuales por sobre 1 entre los valores que presentan el evento.\n\n# figura comparada\nlibrary(ggplot2)\nplot_1 &lt;- broom::augment(m04) %&gt;%\ndplyr::filter(drop == 0) %&gt;%\nggplot(., aes(x=.resid)) + \ngeom_histogram() +\ntheme_bw() +\ntheme(                                   \n  legend.title = element_blank(),        \n  panel.grid.major.x = element_blank(),\n  panel.grid.minor.x = element_blank(),  \n  panel.grid.minor.y = element_blank(),  \n  panel.grid.major.y = element_blank()\n  )     +\nxlab('Residuales (Deviance)')\n\nplot_2 &lt;- broom::augment(m04) %&gt;%\ndplyr::filter(drop == 1) %&gt;%\nggplot(., aes(x=.resid)) + \ngeom_histogram() +\ntheme_bw() +\ntheme(                                   \n  legend.title = element_blank(),        \n  panel.grid.major.x = element_blank(),\n  panel.grid.minor.x = element_blank(),  \n  panel.grid.minor.y = element_blank(),  \n  panel.grid.major.y = element_blank()\n  )     +\nxlab('Residuales (Deviance)')\n\n# reorganizar las figuras generadas\nplot_in_wide &lt;- cowplot::plot_grid(\n    plot_1 + \n      ggtitle('Residuales entre\\nobservaciones que no presentan el evento') + \n      theme(legend.position = 'none'),\n    plot_2 + \n      ggtitle('Residuales entre\\nobservaciones que sí presentan el evento') + \n      theme(legend.position = 'none'),\n    ncol=2, nrow = 1\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n# mostrar a las figuras generadas\nplot_in_wide"
  },
  {
    "objectID": "logit_results.html#anexo-3-efectos-marginales-average-marginal-effects",
    "href": "logit_results.html#anexo-3-efectos-marginales-average-marginal-effects",
    "title": "Regresión logística en R",
    "section": "Anexo 3: Efectos marginales (Average Marginal Effects)",
    "text": "Anexo 3: Efectos marginales (Average Marginal Effects)\nComo fuera visto en clase podemos obtener los efectos marginales, en particular los average marginal effects. Estos nos entregan el cambio esperado en escala de probabilidad, por sobre el promedio, para cada unidad sobre cada covariable del mdoelo. Sin embargo, en esta guía empleamos probabilidades condicionales esperadas a valores particulares para ilustrar los resultados esperados, siguiendo a Osborne (2012).\n\n# efectos marginales (average marginal effects)\nmarginaleffects::avg_slopes(m04)\n\n\n Term Estimate Std. Error      z Pr(&gt;|z|)     S   2.5 %   97.5 %\n int   -0.0148    0.00367  -4.04   &lt;0.001  14.2 -0.0220 -0.00763\n zach  -0.0832    0.00401 -20.76   &lt;0.001 315.5 -0.0911 -0.07536\n zses  -0.0607    0.00391 -15.53   &lt;0.001 178.3 -0.0684 -0.05306\n\nType:  response \nComparison: mean(dY/dX)\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nPara más detalles de que son estas probabilidades condicionales, y como se obvtienen se recomienda consultar Heiss (2018)."
  },
  {
    "objectID": "edu4046_mod.html",
    "href": "edu4046_mod.html",
    "title": "Interacción entre variables",
    "section": "",
    "text": "Cuando estudiamos las relaciones de covariables con respecto a una variable de respuesta existe un escenario particular, donde las relaciones pueden no ser constantes. Es decir, que la relación de una covariable con respecto a la variable de respuesta, puede aumentar, o disminuir con respecto a los valores de una tercera variable.\nEn la investigación educación existen diversas aplicaciones donde este escenario es de interés:\n\n\npodemos estar interesados en buscar factores protectores para la brecha socioeconómica de los resultados académicos de los estudiantes.\n\n\npodemos estar evaluando el efecto de un programa de intervención, y tener dudas razonables respecto a si el programa es efectivo para todos los estudiantes.\n\n\npodemos estar estudiando cómo funciona una práctica escolar, y podríamos querer saber si opera de forma compensatoria con respecto a los estudiantes más vulnerables.\n\n\npodemos estar estudiando cómo funciona una práctica escolar, y podríamos querer evaluar si la práctica es igual de beneficiosa para estudiantes hombres y mujeres.\n\n\npodríamos estar interesados en sí la introducción de incentivos salariales para profesores en escuelas vulnerables promueve la retención de profesores en estas escuelas (a niveles similares al resto de las escuelas).\n\n\nEn todos los ejemplos anteriores podemos separar nuestras expectativas de resultados en al menos dos elementos:\n\n\ntenemos una relacion principal entre dos variables (la variable de respuesta, y una covariable).\n\n\nqueremos ver si esta relación principal cambia segun un tercer factor\n\n\nUna herramienta que nos sirve para estudiar si la relación entre dos variable cambia en relación a un tercer factor son las interacciones entre variables. Esta herramienta nos permite evaluar si una relación de interés entre dos variables es constante o no, a los valores de una tercera variable. Este tipo de modelos es muy común en el estudio de efectividad escolar, en el estudio de evaluación de programas, y en el estudio general de inequidad escolar."
  },
  {
    "objectID": "edu4046_mod.html#medias-condicionadas",
    "href": "edu4046_mod.html#medias-condicionadas",
    "title": "Interacción entre variables",
    "section": "Medias condicionadas",
    "text": "Medias condicionadas\nLos modelos de regresión los podemos pensar como modelos de medias condicionadas. En términos gráficos nos tenemos que imaginar que tenemos una media y condicional a los valores de otro atributo la media de la variable de respuesta puede tomar diferentes valores o posiciones.\nComencemos con un ejemplo de tres variables. Supongamos que tenemos los puntajes de un test que expresa habilidad matemática (e.g., capacidad de resolución de problemas matemáticos de sexto grado), y denominemos a este puntaje como \\(y_{i}\\). Que un modelo de regresión sea pensado como un modelo de medias condicionadas, nos permite indicar que podemos expresar diferentes puntos del puntaje total anterior, segun los valores de otras covariables (i.e., condicional a…). Por ejemplo, que contamos con la escolaridad de los padres de los estudiantes, para los cuales tenemos los puntajes de habilidad. Empleemos a la variable \\(x_{i}\\) para alojar a los valores de escolaridad de los padres (e.g., 1 para educación terciaria, y 0 para grados educativos menores a la educación terciaria.). Y finalmente, agreguemos un tercer factor: la dependencia de la escuelas a las que asisten los estudiantes. Designemos esta tercera variable mediante \\(w_{i}\\), y para este ejemplo vamos a emplear los valores cero para las escuelas públicas, y los valores uno para los estudiantes que asisten a escuelas privadas.\nPara ilustrar la idea de las medias condicionadas, comencemos con un escenario sencillo. En este primer escenario vamos a imaginarnos que no hay diferencias ni por la escolaridad de los padres de los estudiantes, y que tampoco hay diferencias condicional a la escuela a la que asisten los estudiantes. En este escenario, lo más informativo de los puntajes observados sería la media de los puntajes de matemáticas. Vamos a dejar este punto de referencia en 700 puntos.\n\nCode#---------------------------------------------------------------\n# figure\n#---------------------------------------------------------------\n\n#--------------------------------------\n# ideal effects\n#--------------------------------------\n\nb0 &lt;- 700.000\nb1 &lt;- 100.000\nb2 &lt;- 100.000\nb3 &lt;- 100.000\n\n#--------------------------------------\n# no differences\n#--------------------------------------\n\nset.seed(321)\nlibrary(dplyr)\nlibrary(simglm)\n\nsample_size &lt;- 4500\nsim_arguments &lt;- list(\n  formula = y ~ 1 + x + w + x*w,\n  fixed = list(\n               x = list(var_type = 'factor', levels = c(0, 1)),\n               w = list(var_type = 'factor', levels = c(0, 1))\n               ),\n  error = list(variance = 6350.643),\n  sample_size = sample_size,\n  reg_weights = c(\n    b0*1  , # b0\n    b1*0  , # b1\n    b2*0  , # b2\n    b3*0    # b3\n    )\n)\n\ndata_example_1 &lt;- simulate_fixed(data = NULL, sim_arguments) %&gt;%\nsimulate_error(sim_arguments) %&gt;%\ngenerate_response(sim_arguments)\n\n#--------------------------------------\n# bar plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\ndata_example_1 %&gt;%\ngroup_by(x,w) %&gt;%\nsummarize(\ny = mean(y, na.rm =TRUE)\n) %&gt;%\nungroup() %&gt;%\nmutate(dependencia = case_when(\nw == 1 ~ 'Privada',\nw == 0 ~ 'Pública'\n)) %&gt;%\nmutate(dependencia = factor(dependencia, \n  levels = c(\n    'Pública',\n    'Privada'\n    ))) %&gt;%\nmutate(escolaridad = case_when(\nx == 1 ~ 'Terciaria',\nx == 0 ~ 'No terciaria'\n)) %&gt;%\nmutate(escolaridad = factor(escolaridad, \n  levels = c(\n    'No terciaria',\n    'Terciaria'\n    ))) %&gt;%\nggplot(., \n  aes(\n    y = y,\n    x = escolaridad,\n    fill = dependencia\n    )) +\ngeom_bar(position=\"dodge\", stat=\"identity\") +\nscale_y_continuous(\n  breaks = seq(0, 1100, by = 100),\n  limits = c(0, 1100)\n) +\ntheme_ipsum() +\nylab('Matemáticas') +\nscale_fill_manual(\nvalues = c(\n'Pública' = 'black',\n'Privada' = 'red'\n))\n\n\n\nEscenario 1: sin diferencias\n\n\n\nEn este primer escenario, formalmente estamos planteando que las medias de los cuatro grupos posibles son similares entre sí. Y por tanto, que hay diferencias o desplazamientos de la media grupal, condicional a los valores de los factores de interés ( \\(x_{i}\\) y \\(w_{i}\\)).\nAhora nos vamos imaginarnos un segundo escenario. En este segundo escenario, solo vamos a tener diferencias por la escolaridad de los padres de los estudiantes, pero nos vamos a imaginar que no hay diferencias condicionales a las escuela a la que asisten los estudiantes. De esta forma, la brecha de puntajes entre estudiantes con padres de diferente escolaridad, no varía según al tipo de escuela a la que asisten.\n\nCode#---------------------------------------------------------------\n# figure\n#---------------------------------------------------------------\n\n#--------------------------------------\n# ideal effects\n#--------------------------------------\n\nb0 &lt;- 700.000\nb1 &lt;- 100.000\nb2 &lt;- 100.000\nb3 &lt;- 100.000\n\n#--------------------------------------\n# no differences\n#--------------------------------------\n\nset.seed(321)\nlibrary(dplyr)\nlibrary(simglm)\n\nsample_size &lt;- 4500\nsim_arguments &lt;- list(\n  formula = y ~ 1 + x + w + x*w,\n  fixed = list(\n               x = list(var_type = 'factor', levels = c(0, 1)),\n               w = list(var_type = 'factor', levels = c(0, 1))\n               ),\n  error = list(variance = 6350.643),\n  sample_size = sample_size,\n  reg_weights = c(\n    b0*1  , # b0\n    b1*1  , # b1\n    b2*0  , # b2\n    b3*0    # b3\n    )\n)\n\ndata_example_2 &lt;- simulate_fixed(data = NULL, sim_arguments) %&gt;%\nsimulate_error(sim_arguments) %&gt;%\ngenerate_response(sim_arguments)\n\n#--------------------------------------\n# bar plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\ndata_example_2 %&gt;%\ngroup_by(x,w) %&gt;%\nsummarize(\ny = mean(y, na.rm =TRUE)\n) %&gt;%\nungroup() %&gt;%\nmutate(dependencia = case_when(\nw == 1 ~ 'Privada',\nw == 0 ~ 'Pública'\n)) %&gt;%\nmutate(escolaridad = case_when(\nx == 1 ~ 'Terciaria',\nx == 0 ~ 'No terciaria'\n)) %&gt;%\nggplot(., \n  aes(\n    y = y,\n    x = escolaridad,\n    fill = dependencia\n    )) +\ngeom_bar(position=\"dodge\", stat=\"identity\") +\nscale_y_continuous(\n  breaks = seq(0, 1100, by = 100),\n  limits = c(0, 1100)\n) +\ntheme_ipsum() +\nylab('Matemáticas') +\nscale_fill_manual(\nvalues = c(\n'Privada' = 'black',\n'Pública' = 'red'\n))\n\n\n\nEscenario 2: solo diferencias respecto a x\n\n\n\nEn este segundo escenario solo tenemos una relación principal. Los valores de los puntajes de matemáticas ( \\(y_{i}\\) ), varían condicional a los valores de \\(x_{i}\\); pero no varían segun los valores de \\(w_{i}\\).\nSigamos con el ejemplo, e imaginemos un tercer escenario. En este escenario vamos a incluir efectos principales para cada covariable, o relaciones de interés para cada factor. En este escenario aun no estamos incluyendo una interacción. Esto nos permitirá obtener medias condicionales para los cuatro grupos posibles:\n\nestudiantes hijos de padres sin educación terciaria, que asisten a escuelas públicas\nestudiantes hijos de padres sin educación terciaria, que asisten a escuelas privadadas\nestudiantes hijos de padres con educación terciaria, que asisten a escuelas públicas\nestudiantes hijos de padres con educación terciaria, que asisten a escuelas privadadas\n\n\nCode#---------------------------------------------------------------\n# figure\n#---------------------------------------------------------------\n\n#--------------------------------------\n# ideal effects\n#--------------------------------------\n\nb0 &lt;- 700.000\nb1 &lt;- 100.000\nb2 &lt;- 100.000\nb3 &lt;- 100.000\n\n#--------------------------------------\n# no differences\n#--------------------------------------\n\nset.seed(321)\nlibrary(dplyr)\nlibrary(simglm)\n\nsample_size &lt;- 4500\nsim_arguments &lt;- list(\n  formula = y ~ 1 + x + w + x*w,\n  fixed = list(\n               x = list(var_type = 'factor', levels = c(0, 1)),\n               w = list(var_type = 'factor', levels = c(0, 1))\n               ),\n  error = list(variance = 6350.643),\n  sample_size = sample_size,\n  reg_weights = c(\n    b0*1  , # b0\n    b1*1  , # b1\n    b2*1  , # b2\n    b3*0    # b3\n    )\n)\n\ndata_example_3 &lt;- simulate_fixed(data = NULL, sim_arguments) %&gt;%\nsimulate_error(sim_arguments) %&gt;%\ngenerate_response(sim_arguments)\n\n#--------------------------------------\n# bar plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\ndata_example_3 %&gt;%\ngroup_by(x,w) %&gt;%\nsummarize(\ny = mean(y, na.rm =TRUE)\n) %&gt;%\nungroup() %&gt;%\nmutate(dependencia = case_when(\nw == 1 ~ 'Privada',\nw == 0 ~ 'Pública'\n)) %&gt;%\nmutate(escolaridad = case_when(\nx == 1 ~ 'Terciaria',\nx == 0 ~ 'No terciaria'\n)) %&gt;%\nggplot(., \n  aes(\n    y = y,\n    x = escolaridad,\n    fill = dependencia\n    )) +\ngeom_bar(position=\"dodge\", stat=\"identity\") +\nscale_y_continuous(\n  breaks = seq(0, 1100, by = 100),\n  limits = c(0, 1100)\n) +\ntheme_ipsum() +\nylab('Matemáticas') +\nscale_fill_manual(\nvalues = c(\n'Privada' = 'black',\n'Pública' = 'red'\n))\n\n\n\nEscenario 3: diferencias respecto a x y w, pero sin interacción\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEn este documento empleamos los términos efecto y efectos principales para referirnos a los parámetros del modelo, que esperamos genere los datos (i.e., data generating mechanism). En otras palabras, nos estamos refiriendo a un aspecto estructural de los modelos que se ajustan (ver Rabe-Hesketh & Skrondal, 2012, p56-59). Esta terminología, es similar en nombre al uso de la expresión efecto como efecto causal que se emplea en la literatura de inferencia causal. No obstante, si bien hay conincidencias de términos, ambas expresiones no significan lo mismo. En el presente documento emplearemos el término efecto solo para aludir a relaciones esperadas entre variables, las cuales estan expresadas en los modelos de regresión y no para aludir al efecto causal que se espera de una variable por sobre otra.\n\n\nEn este tercer escenario las medias se desplazan respecto al punto de referencia inicial, el intercepto. Este desplazamiento ocurre tanto condicional a los valores de \\(x_{i}\\), como condicional a los valores de \\(w_{i}\\). Los estudiantes hijos de padres sin educación terciara presentan medias menores, en contraste a sus pares que asisten a escuelas privadas. En este escenario, observamos diferencias similares, entre los estudiantes hijos de padres con educación terciara. Aquellos que asisten a escuelas privadas, presentan medias de mayor tamaño, en contraste a sus pares que asisten a escuelas públicas.\nAhora, nos vamos a imaginar un cuarto escenario, donde incluímos una interacción entre ambas variables: entre la escolaridad de los padres, y el tipo de escuela al que asisten los estudiantes.\n\nCode#---------------------------------------------------------------\n# figure\n#---------------------------------------------------------------\n\n#--------------------------------------\n# ideal effects\n#--------------------------------------\n\nb0 &lt;- 700.000\nb1 &lt;- 100.000\nb2 &lt;- 100.000\nb3 &lt;- 100.000\n\n#--------------------------------------\n# no differences\n#--------------------------------------\n\nset.seed(321)\nlibrary(dplyr)\nlibrary(simglm)\n\nsample_size &lt;- 4500\nsim_arguments &lt;- list(\n  formula = y ~ 1 + x + w + x*w,\n  fixed = list(\n               x = list(var_type = 'factor', levels = c(0, 1)),\n               w = list(var_type = 'factor', levels = c(0, 1))\n               ),\n  error = list(variance = 6350.643),\n  sample_size = sample_size,\n  reg_weights = c(\n    b0*1  , # b0\n    b1*1  , # b1\n    b2*1  , # b2\n    b3*-1    # b3\n    )\n)\n\ndata_example_4 &lt;- simulate_fixed(data = NULL, sim_arguments) %&gt;%\nsimulate_error(sim_arguments) %&gt;%\ngenerate_response(sim_arguments)\n\n#--------------------------------------\n# bar plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\ndata_example_4 %&gt;%\ngroup_by(x,w) %&gt;%\nsummarize(\ny = mean(y, na.rm =TRUE)\n) %&gt;%\nungroup() %&gt;%\nmutate(dependencia = case_when(\nw == 1 ~ 'Privada',\nw == 0 ~ 'Pública'\n)) %&gt;%\nmutate(escolaridad = case_when(\nx == 1 ~ 'Terciaria',\nx == 0 ~ 'No terciaria'\n)) %&gt;%\nggplot(., \n  aes(\n    y = y,\n    x = escolaridad,\n    fill = dependencia\n    )) +\ngeom_bar(position=\"dodge\", stat=\"identity\") +\nscale_y_continuous(\n  breaks = seq(0, 1100, by = 100),\n  limits = c(0, 1100)\n) +\ntheme_ipsum() +\nylab('Matemáticas') +\nscale_fill_manual(\nvalues = c(\n'Privada' = 'black',\n'Pública' = 'red'\n))\n\n\n\nEscenario 4: diferencias respecto a x y w, y una interacción negativa\n\n\n\nEn este cuarto escenario la brecha entre estudiantes que asiste a escuelas públicas y privadas no posee el mismo tamaño. Entre los estudiantes hijos de padres con escolaridad terciara no se observan diferencias de medias; mientras que entre los estudiantes hijos de padres son educación terciaria observamos una diferencia de 100 puntos.\nFinalmente, en un quinto escenario, vamos a incluir una interacción, pero esta interacción toma una dirección diferente. Mientras en el escenario anterior lo que observabamos condiciones donde la brecha en puntajes de matemáticas entre estudiantes hijos de padres de diferente escolaridad, era nula entre escuelas privadas, y solo se observada entre escuelas públicas; ahora vamos imaginarnos un escenario inverso. En este escenario inverso, vamos a incluir una interacción tal, que la brecha entre los estudiantes, producto de la escolaridad de sus padres es de mayor tamaño entre quieres asisten a escuelas privadas, en contraste entre quienes asisten a escuelas públicas.\n\nCode#---------------------------------------------------------------\n# figure\n#---------------------------------------------------------------\n\n#--------------------------------------\n# ideal effects\n#--------------------------------------\n\nb0 &lt;- 700.000\nb1 &lt;- 100.000\nb2 &lt;- 100.000\nb3 &lt;- 100.000\n\n#--------------------------------------\n# no differences\n#--------------------------------------\n\nset.seed(321)\nlibrary(dplyr)\nlibrary(simglm)\n\nsample_size &lt;- 4500\nsim_arguments &lt;- list(\n  formula = y ~ 1 + x + w + x*w,\n  fixed = list(\n               x = list(var_type = 'factor', levels = c(0, 1)),\n               w = list(var_type = 'factor', levels = c(0, 1))\n               ),\n  error = list(variance = 6350.643),\n  sample_size = sample_size,\n  reg_weights = c(\n    b0*1  , # b0\n    b1*1  , # b1\n    b2*1  , # b2\n    b3*1    # b3\n    )\n)\n\ndata_example_5 &lt;- simulate_fixed(data = NULL, sim_arguments) %&gt;%\nsimulate_error(sim_arguments) %&gt;%\ngenerate_response(sim_arguments)\n\n#--------------------------------------\n# bar plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\ndata_example_5 %&gt;%\ngroup_by(x,w) %&gt;%\nsummarize(\ny = mean(y, na.rm =TRUE)\n) %&gt;%\nungroup() %&gt;%\nmutate(dependencia = case_when(\nw == 1 ~ 'Privada',\nw == 0 ~ 'Pública'\n)) %&gt;%\nmutate(escolaridad = case_when(\nx == 1 ~ 'Terciaria',\nx == 0 ~ 'No terciaria'\n)) %&gt;%\nggplot(., \n  aes(\n    y = y,\n    x = escolaridad,\n    fill = dependencia\n    )) +\ngeom_bar(position=\"dodge\", stat=\"identity\") +\nscale_y_continuous(\n  breaks = seq(0, 1100, by = 100),\n  limits = c(0, 1100)\n) +\ntheme_ipsum() +\nylab('Matemáticas') +\nscale_fill_manual(\nvalues = c(\n'Privada' = 'black',\n'Pública' = 'red'\n))\n\n\n\nEscenario 5: diferencias respecto a x y w, y una interacción positiva\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nDe los cinco escenarios revisados, solo dos de ellos incluyen un término de interacción, el escenario 4 y el escenario 5. En estos escenarios lla brecha o relación entre \\(y_{i}\\) y \\(x_{i}\\) varía según los valores de \\(w_{i}\\). Mientras en el escenario 4 la brecha entre \\(y_{i}\\) y \\(x_{i}\\) se hace mas pequeña al aumentar los valores de \\(w_{i}\\); en el escenario 5 la brecha entre \\(y_{i}\\) y \\(x_{i}\\) es de mayor tamaño al aumentar los valores de \\(w_{i}\\) (de público \\(w_{i} = 0\\) a privado \\(w_{i} = 1\\)).\n\n\nA continuación, vamos a representar de manera formal a los escenarios anteriores."
  },
  {
    "objectID": "edu4046_mod.html#parámetros-definidos",
    "href": "edu4046_mod.html#parámetros-definidos",
    "title": "Interacción entre variables",
    "section": "Parámetros definidos",
    "text": "Parámetros definidos\nEmpleando al modelo de regresión anterior generamos datos para cada uno de los escenarios posibles antes descritos. Definimos los valores de los términos \\(\\beta_{0}\\), \\(\\beta_{1}\\), \\(\\beta_{2}\\) y \\(\\beta_{3}\\), y \\(\\epsilon_{i}\\) para 5 escenarios diferentes. En base a esta definición generamos datos para 4500 observaciones, en una sola realización.\nProdujimos datos simulados para ilustrar diferentes posibilidades de resultados que podríamos tener con conjuntos de relaciones de tres variables en modelos de regresión.\nLos escenarios generados fueron los siguientes:\nEscenario 1: sin diferencias\n\\[y_{i} = 700 + 0*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \\epsilon_{i}\\]\nEscenario 2: solo diferencias por un factor.\n\\[y_{i} = 700 + 100*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \\epsilon_{i}\\]\nEscenario 3: efectos principales sin interacción\n\\[y_{i} = 700 + 100*x_{i} + 100*w_{i} + 0*(x_{i}*w_{i}) + \\epsilon_{i}\\]\nEscenario 4: interacción negativa\n\\[y_{i} = 700 + 100*x_{i} + 100*w_{i} - 100*(x_{i}*w_{i}) + \\epsilon_{i}\\]\nEscenario 5: interacción positiva\n\\[y_{i} = 700 + 100*x_{i} + 100*w_{i} + 100*(x_{i}*w_{i}) + \\epsilon_{i}\\]\nPara cada uno de los escenarios definimos que \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\), donde,\n\n\n\\(\\sigma^2\\) = 6350.643\n\n\n\n\n\n\n\nNota\n\n\n\nPara poder generar datos simulados empleando a los parámetros anteriores library(simglm) (ver LeBau, 2024). Previo a la presentación de cada figura se encuentra el código empleado. Si se hace click sobre el término presentado en gris code, se puede acceder al código empleado."
  },
  {
    "objectID": "edu4046_mod.html#representación-gráfica",
    "href": "edu4046_mod.html#representación-gráfica",
    "title": "Interacción entre variables",
    "section": "Representación gráfica",
    "text": "Representación gráfica\nTradicionalmente la visualización de interacciones emplea gráficos de simple slopes (Bauer, 2005; Preacher et al., 2006). En el caso de las interacciones generadas con variables categóricas de dos valores, estos gráficos incluyen a las medias esperadas de cada grupo, y estas medias son unidas con una linea. La inclinación de estas estas rectas expresan a las pendientes de regresión esperadas.\nA continuación generamos gráficos para los 5 escenarios anteriores empleando este tipo de figuras.\nPara el caso del  escenario 1  el único parámetro informativo es el intercepto, porque este es un escenario en que las variables \\(x_{i}\\) e \\(w_{i}\\) no son informativas respecto a los valores de \\(y_{i}\\).\n\nCode#---------------------------------------------------------------\n# simple slope\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fitted model\n#--------------------------------------\n\nm01 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_1)\n\n#--------------------------------------\n# plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nplot_1 &lt;- interactions::interact_plot(m01, \npred = x, \nmodx = w,\ninterval = TRUE,\ny.label = 'Matemáticas',\nx.label = \n'Educación de los padres\n(No Terciaria = 0,Terciaria = 1)\n',\nmodx.labels = c('Pública','Privada'),\ncolors = c('black','red')\n) +\nscale_y_continuous(\n  breaks = seq(400, 1000, by = 100),\n  limits = c(400, 1000)\n) +\ntheme_ipsum() +\nlabs(\ntitle = 'Escenario 1',\nsubtitle = 'b0 = 700, b1 = 0, b2 = 0, b3 = 0'\n)\n\nplot_1\n\n\n\nEscenario 1: figura sin efectos\n\n\n\nEn el  escenario 2 , solo incluimos un efecto principal, la relación de la variable \\(x_{i}\\) con \\(y_{i}\\). En este escenario podemos indicar que la brecha de puntajes de matemáticas producto de las diferencias de escolaridad de los padres es generalizable a los estudiantes que asisten a ambos tipos de escuelas, tanto públicas como privadas.\n\nCode#---------------------------------------------------------------\n# simple slope\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fitted model\n#--------------------------------------\n\nm02 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_2)\n\n#--------------------------------------\n# plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nplot_2 &lt;- interactions::interact_plot(m02, \npred = x, \nmodx = w,\ninterval = TRUE,\ny.label = 'Matemáticas',\nx.label = \n'Educación de los padres\n(No Terciaria = 0,Terciaria = 1)\n',\nmodx.labels = c('Pública','Privada'),\ncolors = c('black','red')\n) +\nscale_y_continuous(\n  breaks = seq(400, 1000, by = 100),\n  limits = c(400, 1000)\n) +\ntheme_ipsum() +\nlabs(\ntitle = 'Escenario 2',\nsubtitle = 'b0 = 700, b1 = 100, b2 = 0, b3 = 0'\n)\n\nplot_2\n\n\n\nEscenario 2: efecto de x solamente\n\n\n\nEl  escenario 3  consiste de un escenario en que solo observamos efectos principales de los factores estudiados, sin interacción alguna. Es de decir que, los valores de \\(y_{i}\\) varían condicionales a los valores de \\(x_{i}\\) y \\(w_{i}\\), de forma aditiva, sin incluir interacciones entre ambos factores.\nEn términos sustantivos lo anterior implica que los valores esperados de los puntajes de Matemáticas varían entre los estudiantes según la escolaridad de los padres, y según al tipo de escuela a la que asisten, sin que estas relaciones interactúen entre sí.\nEn este tipo de escenarios los gráficos de simple slopes presentan lineas rectas que son paralelas. Lo anterior, es una característica distintiva de este tipo de gráficos cuando hay una ausencia de interacción entre variables. Complementariamente, solo cuando hay interacciones las rectas generadas por este tipo de gráficos se cruzan pueden cruzar.\n\nCode#---------------------------------------------------------------\n# simple slope\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fitted model\n#--------------------------------------\n\nm03 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_3)\n\n#--------------------------------------\n# plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nplot_3 &lt;- interactions::interact_plot(m03, \npred = x, \nmodx = w,\ninterval = TRUE,\ny.label = 'Matemáticas',\nx.label = \n'Educación de los padres\n(No Terciaria = 0,Terciaria = 1)\n',\nmodx.labels = c('Pública','Privada'),\ncolors = c('black','red')\n) +\nscale_y_continuous(\n  breaks = seq(400, 1000, by = 100),\n  limits = c(400, 1000)\n) +\ntheme_ipsum() +\nlabs(\ntitle = 'Escenario 3',\nsubtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = 0'\n)\n\nplot_3\n\n\n\nEscenario 3: efecto de x e w sin interacción\n\n\n\nEn el  escenario 4, es el primer escenario donde en un sistema de 3 variables incluimos una interacción entre las covariables incluidas en el modelo. En este caso, no podemos decir que la relación entre \\(y_{i}\\) y \\(x_{i}\\) es generalizable a los diferentes valores observados de \\(w_{i}\\).\nEn términos sustantivos, los resultados implican que no hay brecha en los puntajes de matemáticas de los estudiantes condicionales a la escolaridad de los padres, para aquellos estudiantes que asisten a escuelas privadas. Sin embargo, si observamos una brecha entre los estudiantes hijos de padres con diferentes grados educativos. Aquellos estudiantes hijos de padres sin educación terciaria, presentan medias de cerca de 700 puntos, en contraste a sus pares hijos de padres con mayor escolaridad (educación terciaria), los cuales presentan medias de cerca de 800 puntos.\nComo fuera mencionado anteriormente, solo en casos de interacción entre variables los gráficos de simples slopes, presentan rectas que no son paralelas y que potencialmente se cruzan.\n\nCode#---------------------------------------------------------------\n# simple slope\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fitted model\n#--------------------------------------\n\nm04 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_4)\n\n#--------------------------------------\n# plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nplot_4 &lt;- interactions::interact_plot(m04, \npred = x, \nmodx = w,\ninterval = TRUE,\ny.label = 'Matemáticas',\nx.label = \n'Educación de los padres\n(No Terciaria = 0,Terciaria = 1)\n',\nmodx.labels = c('Pública','Privada'),\ncolors = c('black','red')\n) +\nscale_y_continuous(\n  breaks = seq(400, 1000, by = 100),\n  limits = c(400, 1000)\n) +\ntheme_ipsum() +\nlabs(\ntitle = 'Escenario 4',\nsubtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = -100'\n)\n\nplot_4\n\n\n\nEscenario 4: interacción negativa\n\n\n\nFinalmente, en el escenario 5 incluimos un efecto de interacción. En este caso, es una interacción positiva que se espera que aumente las brechas observadas entre \\(y_{i}\\) y \\(x_{i}\\), condicional a los valores de \\(w_{i}\\).\nEn términos sustantivos, los resultados de este escenario nos indican que la brecha en los puntajes de matemáticas relativa a la escolaridad de los padres, es de mayor tamaño entre los estudiantes que asisten a escuelas privadas, en contraste a los estudiantes que asisten a escuelas públicas.\nLos gráficos de simple slope, para este tipo de escenarios muestran rectas que se cruzan, y que se abren a medida que aumentan los valores de \\(x_{i}\\).\n\nCode#---------------------------------------------------------------\n# simple slope\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fitted model\n#--------------------------------------\n\nm05 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_5)\n\n#--------------------------------------\n# plot\n#--------------------------------------\n\nlibrary(ggplot2)\nlibrary(hrbrthemes)\nplot_5 &lt;- interactions::interact_plot(m05, \npred = x, \nmodx = w,\ninterval = TRUE,\ny.label = 'Matemáticas',\nx.label = \n'Educación de los padres\n(No Terciaria = 0,Terciaria = 1)\n',\nmodx.labels = c('Pública','Privada'),\ncolors = c('black','red')\n) +\nscale_y_continuous(\n  breaks = seq(400, 1000, by = 100),\n  limits = c(400, 1000)\n) +\ntheme_ipsum() +\nlabs(\ntitle = 'Escenario 5',\nsubtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = 100'\n)\n\nplot_5\n\n\n\nEscenario 1: figura sin efectos"
  },
  {
    "objectID": "edu4046_mod.html#estimados-de-regresión",
    "href": "edu4046_mod.html#estimados-de-regresión",
    "title": "Interacción entre variables",
    "section": "Estimados de regresión",
    "text": "Estimados de regresión\nA continuación vamos a ajustar modelos de regresión sobre los datos generados empleados en los escenarios 1 a 5. Como los datos sobre los que ajustaremos los modelos son datos simulados, de una sola realización del modelo definido o mecanismos generador datos, los resultados obtenidos van a ser muy parecidos a los parámetros definidos; pero no exactamente iguales.\nEsta diferencia entre el parámetro del modelo y el estimado del modelo suele simbolizarse mediante acentos en la notación. Por ejemplo el parámetro que expresa a la relación entre \\(y_{i}\\) e \\(x_{i}\\) es \\(\\beta_{1}\\), mientras que el estimado de esta relación es \\(\\hat{\\beta}_{1}\\).\nEl siguiente ejercicio nos servirá para ilustrar como serían los modelos de regresión que se pueden ajustar sobre los datos que generan a las figuras de los 5 escenarios anteriores.\n\nCode#---------------------------------------------------------------\n# regression\n#---------------------------------------------------------------\n\n#--------------------------------------\n# fit models\n#--------------------------------------\n\nm01 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_1)\nm02 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_2)\nm03 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_3)\nm04 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_4)\nm05 &lt;- lm(y ~ 1 + x + w + x*w, data = data_example_5)\n\n#--------------------------------------\n# estimates\n#--------------------------------------\n\ntexreg::screenreg(list(m01, m02, m03, m04, m05), \n  star.symbol = \"*\", \n  center = TRUE, \n  doctype = FALSE,\n  dcolumn = TRUE, \n  booktabs = TRUE,\n  single.row = FALSE,\n  custom.model.names = c('E1','E2','E3','E4','E5'))\n\n\n============================================================================\n             E1           E2           E3           E4           E5         \n----------------------------------------------------------------------------\n(Intercept)   699.14 ***   699.14 ***   699.14 ***   699.14 ***   699.14 ***\n               (2.32)       (2.32)       (2.32)       (2.32)       (2.32)   \nx               0.81       100.81 ***   100.81 ***   100.81 ***   100.81 ***\n               (3.35)       (3.35)       (3.35)       (3.35)       (3.35)   \nw              -0.80        -0.80        99.20 ***    99.20 ***    99.20 ***\n               (3.29)       (3.29)       (3.29)       (3.29)       (3.29)   \nx:w             2.02         2.02         2.02       -97.98 ***   102.02 ***\n               (4.71)       (4.71)       (4.71)       (4.71)       (4.71)   \n----------------------------------------------------------------------------\nR^2             0.00         0.29         0.46         0.24         0.66    \nAdj. R^2       -0.00         0.29         0.46         0.24         0.66    \nNum. obs.    4500         4500         4500         4500         4500       \n============================================================================\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05"
  },
  {
    "objectID": "edu4046_mod.html#medias-esperadas-empleando-a-los-resultados-del-modelo-de-regresión",
    "href": "edu4046_mod.html#medias-esperadas-empleando-a-los-resultados-del-modelo-de-regresión",
    "title": "Interacción entre variables",
    "section": "Medias esperadas empleando a los resultados del modelo de regresión",
    "text": "Medias esperadas empleando a los resultados del modelo de regresión\nLa idea general es que con la ecuación de regresión anterior podemos producir valores. Podemos tanto producir valores esperados, como las medias esperadas de los grupos, como los valores esperados por el modelo. Nos vamos a enfocar en las medias esperadas de cada grupo. Ordenando los diferentes términos de la regresión general con interacción podemos obtener las medias esperadas de cada uno de los grupos implicados por ambos factores.\n\nMedia de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas públicas\n\n\\[E(\\bar{y} | x_{i} = 0, w_{i} = 0) = \\beta_{0} + \\beta_{1}*0 + \\beta_{2}*0 + \\beta_{3}*0*0\\]\n\nMedia de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas privadas\n\n\\[E(\\bar{y} | x_{i} = 0, w_{i} = 1) = \\beta_{0} + \\beta_{1}*0 + \\beta_{2}*1 + \\beta_{3}*0*1\\]\n\nMedia de estudiantes con padres de escolaridad terciaria, que asisten a escuelas públicas\n\n\\[E(\\bar{y} | x_{i} = 1, w_{i} = 0) = \\beta_{0} + \\beta_{1}*1 + \\beta_{2}*0 + \\beta_{3}*1*0\\]\n\nMedia de estudiantes con padres de escolaridad terciaria, que asisten a escuelas privadas\n\n\\[E(\\bar{y} | x_{i} = 1, w_{i} = 1) = \\beta_{0} + \\beta_{1}*1 + \\beta_{2}*1 + \\beta_{3}*1*1\\]"
  },
  {
    "objectID": "edu4046_mod.html#terminologia",
    "href": "edu4046_mod.html#terminologia",
    "title": "Interacción entre variables",
    "section": "Terminologia",
    "text": "Terminologia\n\nEfectos principales (i.e., main effects)\nEfectos de interacción (i.e., interaction term)"
  },
  {
    "objectID": "edu4046_mod.html#forma-de-las-interacciones",
    "href": "edu4046_mod.html#forma-de-las-interacciones",
    "title": "Interacción entre variables",
    "section": "Forma de las interacciones",
    "text": "Forma de las interacciones"
  },
  {
    "objectID": "edu4046_mod.html#introducción",
    "href": "edu4046_mod.html#introducción",
    "title": "Interacción entre variables",
    "section": "Introducción",
    "text": "Introducción"
  },
  {
    "objectID": "edu4046_mod.html#datos",
    "href": "edu4046_mod.html#datos",
    "title": "Interacción entre variables",
    "section": "Datos",
    "text": "Datos"
  },
  {
    "objectID": "edu4046_mod.html#preparar-datos",
    "href": "edu4046_mod.html#preparar-datos",
    "title": "Interacción entre variables",
    "section": "Preparar Datos",
    "text": "Preparar Datos"
  },
  {
    "objectID": "edu4046_mod.html#ajustar-modelo",
    "href": "edu4046_mod.html#ajustar-modelo",
    "title": "Interacción entre variables",
    "section": "Ajustar Modelo",
    "text": "Ajustar Modelo"
  },
  {
    "objectID": "edu4046_mod.html#tabla-de-resultados",
    "href": "edu4046_mod.html#tabla-de-resultados",
    "title": "Interacción entre variables",
    "section": "Tabla de resultados",
    "text": "Tabla de resultados"
  },
  {
    "objectID": "edu4046_mod.html#descripción-de-resultados",
    "href": "edu4046_mod.html#descripción-de-resultados",
    "title": "Interacción entre variables",
    "section": "Descripción de resultados",
    "text": "Descripción de resultados"
  },
  {
    "objectID": "edu4046_mod.html#interacciones-entre-dicotómicas",
    "href": "edu4046_mod.html#interacciones-entre-dicotómicas",
    "title": "Interacción entre variables",
    "section": "Interacciones entre dicotómicas",
    "text": "Interacciones entre dicotómicas"
  },
  {
    "objectID": "edu4046_mod.html#interacciones-entre-dicotómicas-y-continuas",
    "href": "edu4046_mod.html#interacciones-entre-dicotómicas-y-continuas",
    "title": "Interacción entre variables",
    "section": "Interacciones entre dicotómicas y continuas",
    "text": "Interacciones entre dicotómicas y continuas"
  },
  {
    "objectID": "edu4046_mod.html#interacciones-entre-continuas",
    "href": "edu4046_mod.html#interacciones-entre-continuas",
    "title": "Interacción entre variables",
    "section": "Interacciones entre continuas",
    "text": "Interacciones entre continuas"
  },
  {
    "objectID": "edu4046_mod.html#inferencia-en-interacciones",
    "href": "edu4046_mod.html#inferencia-en-interacciones",
    "title": "Interacción entre variables",
    "section": "Inferencia en interacciones",
    "text": "Inferencia en interacciones"
  },
  {
    "objectID": "edu4046_mod.html#poder-estadístico",
    "href": "edu4046_mod.html#poder-estadístico",
    "title": "Interacción entre variables",
    "section": "Poder estadístico",
    "text": "Poder estadístico"
  },
  {
    "objectID": "edu4046_mod.html#modelos-alternativos-para-evaluar-interacciones",
    "href": "edu4046_mod.html#modelos-alternativos-para-evaluar-interacciones",
    "title": "Interacción entre variables",
    "section": "Modelos alternativos para evaluar interacciones",
    "text": "Modelos alternativos para evaluar interacciones"
  },
  {
    "objectID": "edu4046_mod.html#interacciones-en-modelos-generalizados",
    "href": "edu4046_mod.html#interacciones-en-modelos-generalizados",
    "title": "Interacción entre variables",
    "section": "Interacciones en modelos generalizados",
    "text": "Interacciones en modelos generalizados"
  },
  {
    "objectID": "edu4046_mod.html#texto-sin-editar",
    "href": "edu4046_mod.html#texto-sin-editar",
    "title": "Interacción entre variables",
    "section": "Texto sin editar",
    "text": "Texto sin editar\nDiagrama Conceptual\nDiagrama de vías\nDescriptivamente, podemos calcular las medias de ambos grupos de estudiantes, y ademas, podríamos calcular la diferencia de medias entre ambos grupos, y con lo anterior tener una noción de si los estudiantes difieren en sus puntajes condicional a la escolaridad de sus padres.\nAhora, podemos abordar la misma inquietud empleando un modelo de regresión:\n\\[y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\epsilon_{i}\\]\nDonde,\n\n\\(y_{i}\\) = puntaje total de cada estudiante \\(_{i}\\).\n\\(x_{i}\\) = escolaridad máxima de los padres de cada estudiante \\(_{i}\\).\n\nCon los resultados de un modelo de regresión como el anterior podemos obtener las medias esperadas de cada grupo:\n\nMedia de estudiantes con padres de escolaridad menor a terciaria\n\n\\[\\beta_{0} + \\beta_{1}(x_{i} = 0)\\]\n\nMedia de estudiantes con padres de escolaridad terciaria\n\n\\[\\beta_{0} + \\beta_{1}(x_{i} = 1)\\]\n¿Que pasaría sin incluimos una tercera variable? Si tuvieramos la información de una tercera variable, dado que estamos pensando el modelo de regresión como una forma de expresar medias condicionadas, es que entonces podriamos tener otra diferencia adicional entre grupos. Pensemos en una tercera covariable como la dependencia de la escuelas (e.g., Privadas y Públicas). Para efectos del ejemplo, pensemos que las escuelas privadas toman un valor uno, y las escuelas públicas toman un valor cero.\n\\[y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}w_{i} + \\epsilon_{i}\\]\n\n\n\\(w_{i}\\) = tipo de escuela a la que asisten a los estudiantes \\(_{i}\\), donde 1 son escuelas privadas, y 0 son escuelas públicas.\n\nCon el modelo anterior, solo podemos representar (i.e., asumir) que las medias entre los grupos aumentan o disminuyen con respecto a al intercepto ( \\(\\beta_{0}\\) ), condicional a los valores de \\(x_{i}\\) (i.e. la escolaridad máxima de los padres) y condicional a los valores de \\(w_{i}\\) (i.e., la dependencia administrativa de la escuelas).\nPara poder representar que las medias anteriores son condicionales entre sí o que interactúan, necesitamos incluir un término adicional: el múltiplo de las variables \\(x_{i}\\) e \\(w_{i}\\), es decir \\(x_{i}*w_{i}\\). Este término nos permitirá obtener un coeficiente de regresión adicional, el cual nos permite saber si hay un “exceso” en las diferencias de medias que estamos obteniendo con los coeficientes anteriores. Este “exceso” puede ser positivo o negativo.\nSi incluimos a todos los términos, ahora contamos con un modelo de regresión, el cual incluye a un término de interacción para las variabels \\(x_{i}\\) e \\(w_{i}\\).\n\\[y_{i} = \\beta_{0} + \\beta_{1}x_{i} + \\beta_{2}w_{i} + \\beta_{3}(x_{i}*w_{i})+\\epsilon_{i}\\]\nLa inquietud general que uno busca responder con los modelos de regresión con interacciones consiste en evaluar si la relación entre dos variables es equivalente, cuando consideramos la información de una tercera variable."
  }
]