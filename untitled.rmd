---
title: "Interacción entre variables"
subtitle: "Relaciónes condicionales"
toc: true
toc-expand: true
toc-title: Contenido
author:
  - name: https://dacarras.github.io/
date-modified: last-modified
format:
  html:
    theme: journal
    code-overflow: wrap
    code-line-numbers: true
    code-annotations: below
    code-link: true
    embed-resources: true
    grid:
      sidebar-width: 250px
      body-width: 750px # 950px thinner, 1050px wider
      margin-width: 400px
      gutter-width: 1.5rem
    header-includes: |
      <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
mainfont: Noto Sans
monofont: Source Code Pro
monofontoptions: 
  - Scale = 0.75
---

```{r, echo = FALSE, eval = TRUE, include = FALSE}

#---------------------------------------------------------------
# settings
#---------------------------------------------------------------

# start time
start_time <- Sys.time()

# hide messages from dplyr
suppressPackageStartupMessages(library(dplyr))

# hide NA from knitr table
options(knitr.kable.NA = '')

# suppress dplyr group warnings
options(dplyr.summarise.inform = FALSE)

# center figures
knitr::opts_chunk$set(echo = TRUE, fig.align="center")

#---------------------------------------------------------------
# load example data
#---------------------------------------------------------------

# load('rasch_example.RData')

``` 

# Introdución

Cuando estudiamos las relaciones de **covariables** con respecto a una **variable de respuesta** existe un escenario particular, donde las relaciones pueden no ser constantes. Es decir, que la relación de una covariable con respecto a la variable de respuesta, puede aumentar, o disminuir con respecto a los valores de una tercera variable.

En la investigación educación existen diversas aplicaciones donde este escenario es de interés:

- a) podemos estar interesados en buscar factores protectores para la brecha socioeconómica de los resultados académicos de los estudiantes.

- b) podemos estar evaluando el efecto de un programa de intervención, y tener dudas razonables respecto a si el programa es efectivo para todos los estudiantes.

- c) podemos estar estudiando cómo funciona una práctica escolar, y podríamos querer saber si opera de forma compensatoria con respecto a los estudiantes más vulnerables.

- d) podemos estar estudiando cómo funciona una práctica escolar, y podríamos querer evaluar si la práctica es igual de beneficiosa para estudiantes hombres y mujeres.

- e) podríamos estar interesados en sí la introducción de incentivos salariales para profesores en escuelas vulnerables promueve la retención de profesores en estas escuelas (a niveles similares al resto de las escuelas).

En todos los ejemplos anteriores podemos separar nuestras expectativas de resultados en al menos dos elementos:

- a) tenemos una relacion principal entre dos variables (la variable de respuesta, y una covariable).
- b) queremos ver si esta relación principal cambia segun un tercer factor


Una herramienta que nos sirve para estudiar si la relación entre dos variable *cambia* en relación a un tercer factor son las **interacciones** entre variables. Esta herramienta nos permite evaluar si una relación de interés entre dos variables es constante o no, a los valores de una tercera variable. Este tipo de modelos es muy común en el estudio de efectividad escolar, en el estudio de evaluación de programas, y en el estudio general de inequidad escolar.


# Idea general

## Medias condicionadas

Los modelos de regresión los podemos pensar como modelos de medias condicionadas. En términos gráficos nos tenemos que imaginar que tenemos una media y condicional a los valores de otro atributo la media de la variable de respuesta puede tomar diferentes valores o posiciones.

Comencemos con un ejemplo de tres variables. Supongamos que tenemos los puntajes de un test que expresa habilidad matemática (e.g., capacidad de resolución de problemas matemáticos de sexto grado), y denominemos a este puntaje como $y_{i}$. Que un modelo de regresión sea pensado como un modelo de medias condicionadas, nos permite indicar que podemos expresar diferentes puntos del puntaje total anterior, segun los valores de otras covariables (i.e., *condicional a...*). Por ejemplo, que contamos con la escolaridad de los padres de los estudiantes, para los cuales tenemos los puntajes de habilidad. Empleemos a la variable $x_{i}$ para alojar a los valores de escolaridad de los padres (e.g., 1 para educación terciaria, y 0 para grados educativos menores a la educación terciaria.). Y finalmente, agreguemos un tercer factor: la dependencia de la escuelas a las que asisten los estudiantes. Designemos esta tercera variable mediante $w_{i}$, y para este ejemplo vamos a emplear los valores cero para las escuelas públicas, y los valores uno para los estudiantes que asisten a escuelas privadas.

Para ilustrar la idea de las medias condicionadas, comencemos con un escenario sencillo. En este **primer escenario** vamos a imaginarnos que no hay diferencias ni por la escolaridad de los padres de los estudiantes, y que tampoco hay diferencias condicional a la escuela a la que asisten los estudiantes. En este escenario, lo más informativo de los puntajes observados sería la media de los puntajes de matemáticas. Vamos a dejar este punto de referencia en 700 puntos.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 1: sin diferencias"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*0  , # b1
    b2*0  , # b2
    b3*0    # b3
    )
)

data_example_1 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_1 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

En este primer escenario, formalmente estamos planteando que las medias de los cuatro grupos posibles son similares entre sí. Y por tanto, que hay diferencias o desplazamientos de la media grupal, condicional a los valores de los factores de interés ( $x_{i}$ y $w_{i}$).

Ahora nos vamos imaginarnos un **segundo escenario**. En este segundo escenario, solo vamos a tener diferencias por la escolaridad de los padres de los estudiantes, pero nos vamos a imaginar que no hay diferencias condicionales a las escuela a la que asisten los estudiantes. De esta forma, la brecha de puntajes entre estudiantes con padres de diferente escolaridad, no varía según al tipo de escuela a la que asisten.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 2: solo diferencias respecto a x"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*0  , # b2
    b3*0    # b3
    )
)

data_example_2 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_2 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```
En este segundo escenario solo tenemos una **relación principal**. Los valores de los puntajes de matemáticas ( $y_{i}$ ), varían condicional a los valores de $x_{i}$; pero no varían segun los valores de $w_{i}$.

Sigamos con el ejemplo, e imaginemos un **tercer escenario**. En este escenario vamos a incluir **efectos principales** para cada covariable, o relaciones de interés para cada factor. En este escenario aun no estamos incluyendo una interacción. Esto nos permitirá obtener medias condicionales para los cuatro grupos posibles:

a) estudiantes hijos de padres sin educación terciaria, que asisten a escuelas públicas
b) estudiantes hijos de padres sin educación terciaria, que asisten a escuelas privadadas
c) estudiantes hijos de padres con educación terciaria, que asisten a escuelas públicas
d) estudiantes hijos de padres con educación terciaria, que asisten a escuelas privadadas

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 3: diferencias respecto a x y w, pero sin interacción"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*0    # b3
    )
)

data_example_3 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_3 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

En este tercer escenario las medias *se desplazan* respecto al punto de referencia inicial, el intercepto.  Este desplazamiento ocurre tanto condicional a los valores de $x_{i}$, como condicional a los valores de $w_{i}$. Los estudiantes hijos de padres sin educación terciara presentan medias menores, en contraste a sus pares que asisten a escuelas privadas. En este escenario, observamos diferencias similares, entre los estudiantes hijos de padres con educación terciara. Aquellos que asisten a escuelas privadas, presentan medias de mayor tamaño, en contraste a sus pares que asisten a escuelas públicas.

Ahora, nos vamos a imginar un **cuarto escenario**, donde incluímos una interacción entre ambas variables: entre la escolaridad de los padres, y el tipo de escuela al que asisten los estudiantes.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 4: diferencias respecto a x y w, y una interacción negativa"


#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*-1    # b3
    )
)

data_example_4 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_4 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

En este cuarto escenario la brecha entre estudiantes que asiste a escuelas públicas y privadas no posee el mismo tamaño. Entre los estudiantes hijos de padres con escolaridad terciara no se observan diferencias de medias; mientras que entre los estudiantes hijos de padres son educación terciaria observamos una diferencia de 100 puntos.

Finalmente, en un **quinto escenario**, vamos a incluir una interacción, pero esta interacción toma una dirección diferente. Mientras en el escenario anterior lo que observabamos condiciones donde la brecha en puntajes de matemáticas entre estudiantes hijos de padres de diferente escolaridad, era nula entre escuelas privadas, y solo se observada entre escuelas públicas; ahora vamos imaginarnos un escenario inverso. En este escenario inverso, vamos a incluir una interacción tal, que la brecha entre los estudiantes, producto de la escolaridad de sus padres es de mayor tamaño entre quieres asisten a escuelas privadas, en contraste entre quienes asisten a escuelas públicas.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 5: diferencias respecto a x y w, y una interacción positiva"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*1    # b3
    )
)

data_example_5 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_5 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

::: {.callout-note title="Nota"}

De los cinco escenarios revisados, solo dos de ellos incluyen un efecto de interacción, el escenario 4 y 5. En estos escenarios los la brecha o relación entre $y_{i}$ y $x_{i}$ varía segúm los valores de $w_{i}$. Mientras en el escenario 4 la brecha entre $y_{i}$ y $x_{i}$ se hace mas pequeña al aumentar los valores de $w_{i}$; en el escenario 5 la brecha entre $y_{i}$ y $x_{i}$ es de mayor tamaño al aumentar los valores de $w_{i}$ (de público $w_{i} = 0$ a privado $w_{i} = 1$).

:::


A continuación, vamos a representar de manera formal a los escenarios anteriores.

# Representación Formal

Las diferencias de medias que ilustramos anteriormente, las podemos representar con un modelo de regresión. La ecuación general de regresión que nos permite representar a los escenarios anteriores toma la siguiente forma:

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \beta_{3}(x_{i}*w_{i}) + \epsilon_{i}$$

Donde,

- $y_{i}$ = puntaje total de cada estudiante $_{i}$.

- $x_{i}$ = escolaridad máxima de los padres de cada estudiante $_{i}$.

- $w_{i}$ = tipo de escuela a la que asisten a los estudiantes $_{i}$, donde 1 son escuelas privadas, y 0 son escuelas públicas.

- $\beta_{0}$ = es el intercepto del modelo. Esta es la media esperada de $y_{i}$ cuando $x_{i} = 0$ y cuando $w_{i} = 0$. De esta forma, $\beta_{0}$ es la media de los estudiantes hijos de padres sin educación terciaria que asiste a escuelas públicas.

- $\beta_{1}$ = es el coeficiente de regresión que acompaña a $x_{i}$. Este expresa la diferencia de medias entre los estudiantes hijos de padres sin educación terciaria, y con educación terciaria, a valores constantes de $w_{i}$. Dicho de otro modo, este término nos indica el aumento esperado sobre los valores de $y_{i}$ entre $x_{i} = 0$ y $x_{i} = 1$ para a valores constantes de $w_{i}$.

- $\beta_{2}$ = es el coeficiente de regresión que acompaña a $w_{i}$. Este expresa la diferencia de medias entre los estudiantes que asisten a escuelas públicas en contraste a los estudiantes que asisten a escuelas privada, a valores constantes de $x_{i}$. Dicho de otro modo, este término nos indica el aumento esperado sobre los valores de $y_{i}$ entre $w_{i} = 0$ y $w_{i} = 1$ para a valores constantes de $x_{i}$.

- $\beta_{3}$ = es el término de interacción para las variable $x_{i}$ e $w_{i}$. Este término de interacción es difícil de interpretar por si solo. Una heurística útil, es considerar su dirección (i.e. si es positivo o negativo), en relación a la dirección de los coeficientes anteriores. Si es positivo, y los términos anteriores son positivos también se espera que la brecha entre $y_{i}$ e $x_{i}$ aumente, condicional a los valores de $w_{i}$ (como en el escenario 5). En cambio si este término es negativo, y va en dirección contraria a la dirección de las covariables que lo producen, lo que se espera es que la brecha entre $y_{i}$ e $x_{i}$ disminuya, condicional a los valores de $w_{i}$.

## Estimados de los escenarios revisados

Con el modelo anterior y definiendo a los términos  $\beta_{0}$, $\beta_{1}$, $\beta_{2}$ y $\beta_{3}$ generamos los datos de cada uno de los escenarios anteriores. Es decir que, produjimos datos simulados para representar diferentes posibilidades.

**Escenario 1: sin diferencias**

$$y_{i} = 700 + 0*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 2: solo diferencias por escolaridad.**

$$y_{i} = 700 + 100*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 3: efectos principales sin interacción**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 4: interacción negativa**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} - 100*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 5: interacción positiva**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} + 100*(x_{i}*w_{i}) + \epsilon_{i}$$

A continuación vamos a ajustar modelos de regresión sobre los datos generados que constituyen a los escenarios 1 a 5. Como los datos simulados solo incluyen a una realización del modelo o mecanismo generador de datos, los resultados obtenidos van a ser muy parecidos a los modelos definidos, pero no exactamente iguales. Estos ejericio nos servirá para ilustrar como los términos del modelo de regresión anterior se vinculan con las medias esperadas que fueron graficas con las figuras anteriores.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "some text here"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

m01 <- lm(y ~ 1 + x + w + x*w, data = data_example_1)
m02 <- lm(y ~ 1 + x + w + x*w, data = data_example_2)
m03 <- lm(y ~ 1 + x + w + x*w, data = data_example_3)
m04 <- lm(y ~ 1 + x + w + x*w, data = data_example_4)
m05 <- lm(y ~ 1 + x + w + x*w, data = data_example_5)

#--------------------------------------
# ideal effects
#--------------------------------------

texreg::screenreg(list(m01, m02, m03, m04, m05), 
  star.symbol = "*", 
  center = TRUE, 
  doctype = FALSE,
  dcolumn = TRUE, 
  booktabs = TRUE,
  single.row = FALSE,
  custom.model.names = c('E1','E2','E3','E4','E5'))

```


## Medias esperadas empleando a los resultados del modelo de regresión

La idea general es que con la ecuación de regresión anterior podemos producir valores. Podemos tanto producir valores esperados, como las medias esperadas de los grupos, como los valores esperados por el modelo. Nos vamos a enfocar en las medias esperadas de cada grupo. Ordenando los diferentes términos de la regresión general con interacción podemos obtener las medias esperadas de cada uno de los grupos implicados por ambos factores.

- Media de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas públicas

$E(\bar{y} | x_{i} = 0, w_{i} = 0) = \beta_{0} + \beta_{1}*0 + \beta_{2}*0 + \beta_{3}*0*0$

- Media de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas privadas

$E(\bar{y} | x_{i} = 0, w_{i} = 1) = \beta_{0} + \beta_{1}*0 + \beta_{2}*1 + \beta_{3}*0*1$

- Media de estudiantes con padres de escolaridad terciaria, que asisten a escuelas públicas

$E(\bar{y} | x_{i} = 1, w_{i} = 0) = \beta_{0} + \beta_{1}*1 + \beta_{2}*0 + \beta_{3}*1*0$

- Media de estudiantes con padres de escolaridad terciaria, que asisten a escuelas privadas

$E(\bar{y} | x_{i} = 1, w_{i} = 1) = \beta_{0} + \beta_{1}*1 + \beta_{2}*1 + \beta_{3}*1*1$











Diagrama Conceptual

Diagrama de vías








**Descriptivamente**, podemos calcular las medias de ambos grupos de estudiantes, y ademas, podríamos calcular la diferencia de medias entre ambos grupos, y con lo anterior tener una noción de si los estudiantes difieren en sus puntajes *condicional a* la escolaridad de sus padres.

Ahora, podemos abordar la misma inquietud empleando un modelo de regresión:

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}$$

Donde,

- $y_{i}$ = puntaje total de cada estudiante $_{i}$.

- $x_{i}$ = escolaridad máxima de los padres de cada estudiante $_{i}$.

Con los resultados de un modelo de regresión como el anterior podemos obtener las medias esperadas de cada grupo:

- Media de estudiantes con padres de escolaridad menor a terciaria

$\beta_{0} + \beta_{1}(x_{i} = 0)$

- Media de estudiantes con padres de escolaridad terciaria

$\beta_{0} + \beta_{1}(x_{i} = 1)$

**¿Que pasaría sin incluimos una tercera variable?** Si tuvieramos la información de una tercera variable, dado que estamos pensando el modelo de regresión como una forma de expresar medias condicionadas, es que entonces podriamos tener otra diferencia adicional entre grupos. Pensemos en una tercera covariable como la dependencia de la escuelas (e.g., Privadas y Públicas). Para efectos del ejemplo, pensemos que las escuelas privadas toman un valor uno, y las escuelas públicas toman un valor cero.

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \epsilon_{i}$$

- $w_{i}$ = tipo de escuela a la que asisten a los estudiantes $_{i}$, donde 1 son escuelas privadas, y 0 son escuelas públicas.

Con el modelo anterior, solo podemos representar (i.e., asumir) que las medias entre los grupos aumentan o disminuyen con respecto a al intercepto ( $\beta_{0}$ ), condicional a los valores de $x_{i}$ (i.e. la escolaridad máxima de los padres) y condicional a los valores de $w_{i}$ (i.e., la dependencia administrativa de la escuelas).

Para poder representar que las medias anteriores son condicionales entre sí o que **interactúan**, necesitamos incluir un término adicional: el múltiplo de las variables $x_{i}$ e $w_{i}$, es decir $x_{i}*w_{i}$. Este término nos permitirá obtener un coeficiente de regresión adicional, el cual nos permite saber si hay un "exceso" en las diferencias de medias que estamos obteniendo con los coeficientes anteriores. Este "exceso" puede ser positivo o negativo. 

Si incluimos a todos los términos, ahora contamos con un modelo de regresión, el cual incluye a un **término de interacción** para las variabels $x_{i}$ e $w_{i}$.

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \beta_{3}(x_{i}*w_{i})+\epsilon_{i}$$


La inquietud general que uno busca responder con los modelos de regresión con interacciones consiste en evaluar si la relación entre dos variables es equivalente, cuando consideramos la información de una **tercera variable**.




# Ejemplo sustantivo


# Representación Formal

Ecuación

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \beta_{3}(x_{i}*w_{i}) + \epsilon_{i}$$

Diagrama Conceptual

Diagrama de vías

## Terminologia

- Efectos principales (i.e., *main effects*)

- Efectos de interacción (i.e., *interaction term*)

## Forma de las interacciones



# Caso aplicado

## Introducción

## Datos

## Preparar Datos

## Ajustar Modelo

## Tabla de resultados

## Descripción de resultados

# Tópicos en estudios de interacción

## Interacciones entre dicotómicas

## Interacciones entre dicotómicas y continuas

## Interacciones entre continuas

## Inferencia en interacciones

## Poder estadístico

## Modelos alternativos para evaluar interacciones

## Interacciones en modelos generalizados

# Bibliografía anotada

Jaccard, J., Wan, C. K., & Turrisi, R. (1990). The Detection and Interpretation of Interaction Effects Between Continuous Variables in Multiple Regression. Multivariate Behavioral Research, 25(October), 467–478. https://doi.org/10.1207/s15327906mbr2504

Maslowsky, J., Jager, J., & Hemken, D. (2015). Estimating and interpreting latent variable interactions: A tutorial for applying the latent moderated structural equations method. International Journal of Behavioral Development, 39(1), 87–96. https://doi.org/10.1177/0165025414552301

Preacher, K. J., Curran, P. J., & Bauer, D. J. (2006). Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis. Journal of Educational and Behavioral Statistics, 31(3), 437–448. https://doi.org/10.3102/10769986031004437

Aguinis, H., & Gottfredson, R. K. (2010). Best-practice recommendations for estimating interaction effects using moderated multiple regression. Journal of Organizational Behavior, 31(6), 776–786. https://doi.org/10.1002/job.686

Mize, T. D. (2019). Best practices for estimating, interpreting, and presenting nonlinear interaction effects. Sociological Science, 6, 81–117. https://doi.org/10.15195/V6.A4

Curran, P. J., Bauer, D. J., & Willoughby, M. T. (2004). Testing main effects and interactions in latent curve analysis. Psychological Methods, 9(2), 220–237. https://doi.org/10.1037/1082-989X.9.2.220

Sun, R., & Willson, V. L. (2009). Evaluating intercept-slope interactions in latent growth modeling. Structural Equation Modeling, 16(2), 226–244. https://doi.org/10.1080/10705510902751051

Baranger, D. A. A., Finsaas, M. C., Goldstein, B. L., Vize, C. E., Lynam, D. R., & Olino, T. M. (2023). Tutorial: Power Analyses for Interaction Effects in Cross-Sectional Regressions. Advances in Methods and Practices in Psychological Science, 6(3). https://doi.org/10.1177/25152459231187531

Bauer, D. J., & Curran, P. J. (2005). Probing Interactions in Fixed and Multilevel Regression: Inferential and Graphical Techniques. Multivariate Behavioral Research, 40(3), 373–400. https://doi.org/10.1207/s15327906mbr4003_5

León, O. G., & Montero, I. (2001). Cómo explicar el concepto de interacción sin estadística: Análisis gráfico de todos los casos posibles en un diseño 2 x 2. Psicothema, 13(1), 159–165.



# Code exploratory

```{r, echo = FALSE, eval = TRUE, include = FALSE}

#---------------------------------------------------------------
# exploratory
#---------------------------------------------------------------

#--------------------------------------
# codebook
#--------------------------------------

library(dplyr)
erce::erce_2019_qa6 %>%
labelled::lookfor() %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble() %>%
knitr::kable()

#--------------------------------------
# selected variables
#--------------------------------------
library(dplyr)
erce::erce_2019_qa6 %>%
labelled::lookfor() %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble() %>%
dplyr::filter(variable %in% c('MAT_1','EDU', 'DEP')) %>%
dplyr::select(pos, variable, label, levels, value_labels) %>%
knitr::kable()

#--------------------------------------
# load data
#--------------------------------------

library(dplyr)
data_a6 <- erce::erce_2019_qa6 %>%
           erce::remove_labels()

#--------------------------------------
# countries with three and two systems
#--------------------------------------

data_a6 %>%
dplyr::count(COUNTRY, DEP) %>%
knitr::kable()

#--------------------------------------
# example with Colombia
#--------------------------------------

data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
lm(y ~ 1 + x*w, data = .) %>%
summary()


#--------------------------------------
# number of observations
#--------------------------------------

data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
nrow()

#--------------------------------------
# number of observations
#--------------------------------------

data_model <- data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
mutate(xw = x*w)

lavaan_model <- '
y ~ b0*1
y ~ b1*x
y ~ b2*w
y ~ b3*xw

# expected means
m0 := b0 + b1*0 + b2*0 + b3*(0*0)
m1 := b0 + b1*0 + b2*1 + b3*(0*1)
m2 := b0 + b1*1 + b2*0 + b3*(1*0)
m3 := b0 + b1*1 + b2*1 + b3*(1*1)
'


# -----------------------------------------------
# fit model
# -----------------------------------------------

m01 <- lavaan::sem(lavaan_model, 
       mimic = 'MPLUS',
       data = data_model)

# -----------------------------------------------
# display summary
# -----------------------------------------------

lavaan::summary(m01, 
  fit.measures=TRUE,
  standardized=TRUE,
  rsquare=TRUE)


```   

# Simulations

```{r, echo = FALSE, eval = TRUE, warning=FALSE}

#---------------------------------------------------------------
# exploratory
#---------------------------------------------------------------


#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000


#--------------------------------------
# scenario 1: no differences on w
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*0  , # b2
    b3*0    # b3
    )
)

data_1 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# scenario 2: no interaction
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*0    # b3
    )
)

data_2 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# scenario 3: negative interaction
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*-1   # b3
    )
)

data_3 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# scenario 4: positive interaction
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*1    # b3
    )
)

data_4 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# fit models
#--------------------------------------

# scenario 1: no effect for w
model_1 <- data_1 %>%
lm(y ~ 1 + x*w, data = .)

# scenario 2: no interaction for w
model_2 <- data_2 %>%
lm(y ~ 1 + x*w, data = .)

# scenario 3: negative interaction
model_3 <- data_3 %>%
lm(y ~ 1 + x*w, data = .)

# scenario 4: positive interaction
model_4 <- data_4 %>%
lm(y ~ 1 + x*w, data = .)


#--------------------------------------
# plots
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_1 <- interactions::interact_plot(model_1, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Panel A',
subtitle = 'Escenario 1: b1 = +, b2 = 0, b3 = 0'
)

plot_1


library(ggplot2)
library(hrbrthemes)
plot_2 <- interactions::interact_plot(model_2, 
pred = x, 
modx = w,
interval = TRUE,
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
y.label = 'Matemáticas',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Panel B',
subtitle = 'Escenario 2: b1 = +, b2 = +, b3 = 0'
)


plot_2

library(ggplot2)
library(hrbrthemes)
plot_3 <- interactions::interact_plot(model_3, 
pred = x, 
modx = w,
interval = TRUE,
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
y.label = 'Matemáticas',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Panel C',
subtitle = 'Escenario 3: b1 = +, b2 = +, b3 = -'
)

plot_3

library(ggplot2)
library(hrbrthemes)
plot_4 <- interactions::interact_plot(model_4, 
pred = x, 
modx = w,
interval = TRUE,
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
y.label = 'Matemáticas',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Panel D',
subtitle = 'Escenario 4: b1 = +, b2 = +, b3 = +'
)

plot_4


#--------------------------------------
# plots
#--------------------------------------


library(cowplot)
plot_grid(
  plot_1, # no differences
  plot_2, # no interaction
  plot_3, # negative interaction
  plot_4, # real
  nrow = 2, 
  ncol = 2
)


#--------------------------------------
# Bar Plot
#--------------------------------------

data_4 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```


