---
title: "Interacción entre variables"
subtitle: "Relaciónes condicionales"
toc: true
toc-expand: true
toc-title: Contenido
author:
  - name: https://dacarras.github.io/
date-modified: last-modified
format:
  html:
    theme: journal
code-overflow: wrap
code-line-numbers: true
code-annotations: below
code-link: true
embed-resources: true
grid:
  sidebar-width: 250px
  body-width: 750px # 950px thinner, 1050px wider
  margin-width: 400px
  gutter-width: 1.5rem
header-includes: |
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
mainfont: Noto Sans
monofont: Source Code Pro
monofontoptions: 
  - Scale = 0.75
---

```{r, echo = FALSE, eval = TRUE, include = FALSE}

#---------------------------------------------------------------
# settings
#---------------------------------------------------------------

# start time
start_time <- Sys.time()

# hide messages from dplyr
suppressPackageStartupMessages(library(dplyr))

# hide NA from knitr table
options(knitr.kable.NA = '')

# suppress dplyr group warnings
options(dplyr.summarise.inform = FALSE)

# center figures
knitr::opts_chunk$set(echo = TRUE, fig.align="center")

#---------------------------------------------------------------
# load example data
#---------------------------------------------------------------

# load('rasch_example.RData')

```

# Introdución

Cuando estudiamos las relaciones de **covariables** con respecto a una **variable de respuesta** existe un escenario particular, donde las relaciones pueden no ser constantes. Es decir, que la relación de una covariable con respecto a la variable de respuesta, puede aumentar, o disminuir con respecto a los valores de una tercera variable.

En la investigación educación existen diversas aplicaciones donde este escenario es de interés:

- a) podemos estar interesados en buscar factores protectores para la brecha socioeconómica de los resultados académicos de los estudiantes.

- b) podemos estar evaluando el efecto de un programa de intervención, y tener dudas razonables respecto a si el programa es efectivo para todos los estudiantes.

- c) podemos estar estudiando cómo funciona una práctica escolar, y podríamos querer saber si opera de forma compensatoria con respecto a los estudiantes más vulnerables.

- d) podemos estar estudiando cómo funciona una práctica escolar, y podríamos querer evaluar si la práctica es igual de beneficiosa para estudiantes hombres y mujeres.

- e) podríamos estar interesados en sí la introducción de incentivos salariales para profesores en escuelas vulnerables promueve la retención de profesores en estas escuelas (a niveles similares al resto de las escuelas).

En todos los ejemplos anteriores podemos separar nuestras expectativas de resultados en al menos dos elementos:

- a) tenemos una relacion principal entre dos variables (la variable de respuesta, y una covariable).
- b) queremos ver si esta relación principal cambia segun un tercer factor


Una herramienta que nos sirve para estudiar si la relación entre dos variable *cambia* en relación a un tercer factor son las **interacciones** entre variables. Esta herramienta nos permite evaluar si una relación de interés entre dos variables es constante o no, a los valores de una tercera variable. Este tipo de modelos es muy común en el estudio de efectividad escolar, en el estudio de evaluación de programas, y en el estudio general de inequidad escolar.


# Idea general

## Medias condicionadas

Los modelos de regresión los podemos pensar como modelos de medias condicionadas. En términos gráficos nos tenemos que imaginar que tenemos una media y condicional a los valores de otro atributo la media de la variable de respuesta puede tomar diferentes valores o posiciones.

Comencemos con un ejemplo de tres variables. Supongamos que tenemos los puntajes de un test que expresa habilidad matemática (e.g., capacidad de resolución de problemas matemáticos de sexto grado), y denominemos a este puntaje como $y_{i}$. Que un modelo de regresión sea pensado como un modelo de medias condicionadas, nos permite indicar que podemos expresar diferentes puntos del puntaje total anterior, segun los valores de otras covariables (i.e., *condicional a...*). Por ejemplo, que contamos con la escolaridad de los padres de los estudiantes, para los cuales tenemos los puntajes de habilidad. Empleemos a la variable $x_{i}$ para alojar a los valores de escolaridad de los padres (e.g., 1 para educación terciaria, y 0 para grados educativos menores a la educación terciaria.). Y finalmente, agreguemos un tercer factor: la dependencia de la escuelas a las que asisten los estudiantes. Designemos esta tercera variable mediante $w_{i}$, y para este ejemplo vamos a emplear los valores cero para las escuelas públicas, y los valores uno para los estudiantes que asisten a escuelas privadas.

Para ilustrar la idea de las medias condicionadas, comencemos con un escenario sencillo. En este **primer escenario** vamos a imaginarnos que no hay diferencias ni por la escolaridad de los padres de los estudiantes, y que tampoco hay diferencias condicional a la escuela a la que asisten los estudiantes. En este escenario, lo más informativo de los puntajes observados sería la media de los puntajes de matemáticas. Vamos a dejar este punto de referencia en 700 puntos.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 1: sin diferencias"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*0  , # b1
    b2*0  , # b2
    b3*0    # b3
    )
)

data_example_1 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_1 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(dependencia = factor(dependencia, 
  levels = c(
    'Pública',
    'Privada'
    ))) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
mutate(escolaridad = factor(escolaridad, 
  levels = c(
    'No terciaria',
    'Terciaria'
    ))) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Pública' = 'black',
'Privada' = 'red'
))


```

En este primer escenario, formalmente estamos planteando que las medias de los cuatro grupos posibles son similares entre sí. Y por tanto, que hay diferencias o desplazamientos de la media grupal, condicional a los valores de los factores de interés ( $x_{i}$ y $w_{i}$).

Ahora nos vamos imaginarnos un **segundo escenario**. En este segundo escenario, solo vamos a tener diferencias por la escolaridad de los padres de los estudiantes, pero nos vamos a imaginar que no hay diferencias condicionales a las escuela a la que asisten los estudiantes. De esta forma, la brecha de puntajes entre estudiantes con padres de diferente escolaridad, no varía según al tipo de escuela a la que asisten.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 2: solo diferencias respecto a x"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*0  , # b2
    b3*0    # b3
    )
)

data_example_2 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_2 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```
En este segundo escenario solo tenemos una **relación principal**. Los valores de los puntajes de matemáticas ( $y_{i}$ ), varían condicional a los valores de $x_{i}$; pero no varían segun los valores de $w_{i}$.

Sigamos con el ejemplo, e imaginemos un **tercer escenario**. En este escenario vamos a incluir **efectos principales** para cada covariable, o relaciones de interés para cada factor. En este escenario aun no estamos incluyendo una interacción. Esto nos permitirá obtener medias condicionales para los cuatro grupos posibles:

a) estudiantes hijos de padres sin educación terciaria, que asisten a escuelas públicas
b) estudiantes hijos de padres sin educación terciaria, que asisten a escuelas privadadas
c) estudiantes hijos de padres con educación terciaria, que asisten a escuelas públicas
d) estudiantes hijos de padres con educación terciaria, que asisten a escuelas privadadas

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 3: diferencias respecto a x y w, pero sin interacción"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*0    # b3
    )
)

data_example_3 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_3 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```
::: {.callout-warning title="Advertencia"}

En este documento empleamos los términos **efecto** y **efectos principales** para referirnos a los parámetros del modelo, que esperamos genere los datos (i.e., *data generating mechanism*). En otras palabras, nos estamos refiriendo a un aspecto estructural de los modelos que se ajustan (ver Rabe-Hesketh & Skrondal, 2012, p56-59). Esta terminología, es similar en nombre al uso de la expresión **efecto** como **efecto causal** que se emplea en la literatura de inferencia causal. No obstante, si bien hay conincidencias de términos, ambas expresiones no significan lo mismo. En el presente documento emplearemos el **término efecto** solo para aludir a relaciones esperadas entre variables, las cuales estan expresadas en los modelos de regresión y no para aludir al efecto causal que se espera de una variable por sobre otra.

:::

En este tercer escenario las medias *se desplazan* respecto al punto de referencia inicial, el intercepto.  Este desplazamiento ocurre tanto condicional a los valores de $x_{i}$, como condicional a los valores de $w_{i}$. Los estudiantes hijos de padres sin educación terciara presentan medias menores, en contraste a sus pares que asisten a escuelas privadas. En este escenario, observamos diferencias similares, entre los estudiantes hijos de padres con educación terciara. Aquellos que asisten a escuelas privadas, presentan medias de mayor tamaño, en contraste a sus pares que asisten a escuelas públicas.

Ahora, nos vamos a imaginar un **cuarto escenario**, donde incluímos una interacción entre ambas variables: entre la escolaridad de los padres, y el tipo de escuela al que asisten los estudiantes.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 4: diferencias respecto a x y w, y una interacción negativa"


#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*-1    # b3
    )
)

data_example_4 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_4 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

En este cuarto escenario la brecha entre estudiantes que asiste a escuelas públicas y privadas no posee el mismo tamaño. Entre los estudiantes hijos de padres con escolaridad terciara no se observan diferencias de medias; mientras que entre los estudiantes hijos de padres son educación terciaria observamos una diferencia de 100 puntos.

Finalmente, en un **quinto escenario**, vamos a incluir una interacción, pero esta interacción toma una dirección diferente. Mientras en el escenario anterior lo que observabamos condiciones donde la brecha en puntajes de matemáticas entre estudiantes hijos de padres de diferente escolaridad, era nula entre escuelas privadas, y solo se observada entre escuelas públicas; ahora vamos imaginarnos un escenario inverso. En este escenario inverso, vamos a incluir una interacción tal, que la brecha entre los estudiantes, producto de la escolaridad de sus padres es de mayor tamaño entre quieres asisten a escuelas privadas, en contraste entre quienes asisten a escuelas públicas.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 5: diferencias respecto a x y w, y una interacción positiva"

#---------------------------------------------------------------
# figure
#---------------------------------------------------------------

#--------------------------------------
# ideal effects
#--------------------------------------

b0 <- 700.000
b1 <- 100.000
b2 <- 100.000
b3 <- 100.000

#--------------------------------------
# no differences
#--------------------------------------

set.seed(321)
library(dplyr)
library(simglm)

sample_size <- 4500
sim_arguments <- list(
  formula = y ~ 1 + x + w + x*w,
  fixed = list(
               x = list(var_type = 'factor', levels = c(0, 1)),
               w = list(var_type = 'factor', levels = c(0, 1))
               ),
  error = list(variance = 6350.643),
  sample_size = sample_size,
  reg_weights = c(
    b0*1  , # b0
    b1*1  , # b1
    b2*1  , # b2
    b3*1    # b3
    )
)

data_example_5 <- simulate_fixed(data = NULL, sim_arguments) %>%
simulate_error(sim_arguments) %>%
generate_response(sim_arguments)

#--------------------------------------
# bar plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
data_example_5 %>%
group_by(x,w) %>%
summarize(
y = mean(y, na.rm =TRUE)
) %>%
ungroup() %>%
mutate(dependencia = case_when(
w == 1 ~ 'Privada',
w == 0 ~ 'Pública'
)) %>%
mutate(escolaridad = case_when(
x == 1 ~ 'Terciaria',
x == 0 ~ 'No terciaria'
)) %>%
ggplot(., 
  aes(
    y = y,
    x = escolaridad,
    fill = dependencia
    )) +
geom_bar(position="dodge", stat="identity") +
scale_y_continuous(
  breaks = seq(0, 1100, by = 100),
  limits = c(0, 1100)
) +
theme_ipsum() +
ylab('Matemáticas') +
scale_fill_manual(
values = c(
'Privada' = 'black',
'Pública' = 'red'
))


```

::: {.callout-note title="Nota"}

De los cinco escenarios revisados, solo dos de ellos incluyen un término de interacción, el escenario 4 y el escenario 5. En estos escenarios lla brecha o relación entre $y_{i}$ y $x_{i}$ varía según los valores de $w_{i}$. Mientras en el escenario 4 la brecha entre $y_{i}$ y $x_{i}$ se hace mas pequeña al aumentar los valores de $w_{i}$; en el escenario 5 la brecha entre $y_{i}$ y $x_{i}$ es de mayor tamaño al aumentar los valores de $w_{i}$ (de público $w_{i} = 0$ a privado $w_{i} = 1$).
  
:::


A continuación, vamos a representar de manera formal a los escenarios anteriores.

# Representación Formal

Las diferencias de medias que ilustramos anteriormente las podemos obtener con un modelo de regresión. La siguente ecuación de regresión nos permite representar a los escenarios anteriores:

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \beta_{3}(x_{i}*w_{i}) + \epsilon_{i}$$

Donde,

- $y_{i}$ = puntaje total de cada estudiante $_{i}$.

- $x_{i}$ = escolaridad máxima de los padres de cada estudiante $_{i}$.

- $w_{i}$ = tipo de escuela a la que asisten a los estudiantes $_{i}$, donde 1 son escuelas privadas, y 0 son escuelas públicas.

- $\beta_{0}$ = es el intercepto del modelo. Esta es la media esperada de $y_{i}$ cuando $x_{i} = 0$ y cuando $w_{i} = 0$. De esta forma, $\beta_{0}$ es la media de los estudiantes hijos de padres sin educación terciaria que asiste a escuelas públicas.

- $\beta_{1}$ = es el coeficiente de regresión que acompaña a $x_{i}$. Este expresa la diferencia de medias entre los estudiantes hijos de padres sin educación terciaria, y con educación terciaria, a valores constantes de $w_{i}$. Dicho de otro modo, este término nos indica el aumento esperado sobre los valores de $y_{i}$ entre $x_{i} = 0$ y $x_{i} = 1$ para a valores constantes de $w_{i}$.

- $\beta_{2}$ = es el coeficiente de regresión que acompaña a $w_{i}$. Este expresa la diferencia de medias entre los estudiantes que asisten a escuelas públicas en contraste a los estudiantes que asisten a escuelas privada, a valores constantes de $x_{i}$. Dicho de otro modo, este término nos indica el aumento esperado sobre los valores de $y_{i}$ entre $w_{i} = 0$ y $w_{i} = 1$ para a valores constantes de $x_{i}$.

- $\beta_{3}$ = es el término de interacción para las variable $x_{i}$ e $w_{i}$. Este término de interacción es difícil de interpretar por si solo. Una heurística útil, es considerar su dirección (i.e. si es positivo o negativo), en relación a la dirección de los coeficientes anteriores. Si es positivo, y los términos anteriores son positivos también se espera que la brecha entre $y_{i}$ e $x_{i}$ aumente, condicional a los valores de $w_{i}$ (como en el escenario 5). En cambio si este término es negativo, y va en dirección contraria a la dirección de las covariables que lo producen, lo que se espera es que la brecha entre $y_{i}$ e $x_{i}$ disminuya, condicional a los valores de $w_{i}$.

- $\epsilon_{i}$ = son los residuos del modelo. Estos corresponden a las distancias entre los valores observados, respecto a la línea ideal que traza el modelo de regresión sobre los datos. Este termino tiene una media cero, una varianza libre, y posee una distribución normal en el modelo que genera los datos. Este último aspecto del modelo de regresión se expresa de la siguiente forma:


$$\epsilon_i \sim \mathcal{N}(0, \sigma^2)$$


## Parámetros definidos

Empleando al modelo de regresión anterior generamos datos para cada uno de los escenarios posibles antes descritos. Definimos los valores de los términos $\beta_{0}$, $\beta_{1}$, $\beta_{2}$ y $\beta_{3}$, y $\epsilon_{i}$ para 5 escenarios diferentes. En base a esta definición generamos datos para 4500 observaciones, en una sola realización.

Produjimos datos simulados para ilustrar diferentes posibilidades de resultados que podríamos tener con conjuntos de relaciones de tres variables en modelos de regresión.

Los escenarios generados fueron los siguientes:

**Escenario 1: sin diferencias**

$$y_{i} = 700 + 0*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 2: solo diferencias por un factor.**

$$y_{i} = 700 + 100*x_{i} + 0*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 3: efectos principales sin interacción**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} + 0*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 4: interacción negativa**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} - 100*(x_{i}*w_{i}) + \epsilon_{i}$$

**Escenario 5: interacción positiva**

$$y_{i} = 700 + 100*x_{i} + 100*w_{i} + 100*(x_{i}*w_{i}) + \epsilon_{i}$$

Para cada uno de los escenarios definimos que $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$, donde,

- $\sigma^2$ = 6350.643

::: {.callout-note title="Nota"}

Para poder generar datos simulados empleando a los parámetros anteriores `library(simglm)` (ver LeBau, 2024). Previo a la presentación de cada figura se encuentra el código empleado. Si se hace click sobre el término presentado en gris `code`, se puede acceder al código empleado.
  
:::


## Representación gráfica

Tradicionalmente la visualización de interacciones emplea gráficos de _**simple slopes**_ (Bauer, 2005; Preacher et al., 2006). En el caso de las interacciones generadas con variables categóricas de dos valores, estos gráficos incluyen a las medias esperadas de cada grupo, y estas medias son unidas con una linea. La inclinación de estas estas rectas expresan a las pendientes de regresión esperadas.

A continuación generamos gráficos para los 5 escenarios anteriores empleando este tipo de figuras.

Para el caso del ** escenario 1 ** el único parámetro informativo es el intercepto, porque este es un escenario en que las variables $x_{i}$ e $w_{i}$ no son informativas respecto a los valores de $y_{i}$.

```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 1: figura sin efectos"

#---------------------------------------------------------------
# simple slope
#---------------------------------------------------------------

#--------------------------------------
# fitted model
#--------------------------------------

m01 <- lm(y ~ 1 + x + w + x*w, data = data_example_1)

#--------------------------------------
# plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_1 <- interactions::interact_plot(m01, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Escenario 1',
subtitle = 'b0 = 700, b1 = 0, b2 = 0, b3 = 0'
)

plot_1


```

En el ** escenario 2 **, solo incluimos un efecto principal, la relación de la variable $x_{i}$ con $y_{i}$. En este escenario podemos indicar que la brecha de puntajes de matemáticas producto de las diferencias de escolaridad de los padres es generalizable a los estudiantes que asisten a ambos tipos de escuelas, tanto públicas como privadas.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 2: efecto de x solamente"

#---------------------------------------------------------------
# simple slope
#---------------------------------------------------------------

#--------------------------------------
# fitted model
#--------------------------------------

m02 <- lm(y ~ 1 + x + w + x*w, data = data_example_2)

#--------------------------------------
# plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_2 <- interactions::interact_plot(m02, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Escenario 2',
subtitle = 'b0 = 700, b1 = 100, b2 = 0, b3 = 0'
)

plot_2


```

El ** escenario 3 ** consiste de un escenario en que solo observamos efectos principales de los factores estudiados, sin interacción alguna. Es de decir que, los valores de $y_{i}$ varían condicionales a los valores de $x_{i}$ y $w_{i}$, de forma aditiva, sin incluir interacciones entre ambos factores.

En términos sustantivos lo anterior implica que los valores esperados de los puntajes de Matemáticas varían entre los estudiantes según la escolaridad de los padres, y según al tipo de escuela a la que asisten, sin que estas relaciones interactúen entre sí.

En este tipo de escenarios los gráficos de *simple slopes* presentan lineas **rectas que son paralelas**. Lo anterior, es una característica distintiva de este tipo de gráficos cuando hay una ausencia de interacción entre variables. Complementariamente, solo cuando hay interacciones las rectas generadas por este tipo de gráficos se cruzan pueden cruzar.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 3: efecto de x e w sin interacción"

#---------------------------------------------------------------
# simple slope
#---------------------------------------------------------------

#--------------------------------------
# fitted model
#--------------------------------------

m03 <- lm(y ~ 1 + x + w + x*w, data = data_example_3)

#--------------------------------------
# plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_3 <- interactions::interact_plot(m03, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Escenario 3',
subtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = 0'
)

plot_3


```

En el ** escenario 4**, es el primer escenario donde en un sistema de 3 variables incluimos una interacción entre las covariables incluidas en el modelo. En este caso, no podemos decir que la relación entre $y_{i}$ y $x_{i}$ es generalizable a los diferentes valores observados de $w_{i}$.

En términos sustantivos, los resultados implican que no hay brecha en los puntajes de matemáticas de los estudiantes condicionales a la escolaridad de los padres, para aquellos estudiantes que asisten a escuelas privadas. Sin embargo, si observamos una brecha entre los estudiantes hijos de padres con diferentes grados educativos. Aquellos estudiantes hijos de padres sin educación terciaria, presentan medias de cerca de 700 puntos, en contraste a sus pares hijos de padres con mayor escolaridad (educación terciaria), los cuales presentan medias de cerca de 800 puntos.

Como fuera mencionado anteriormente, solo en casos de interacción entre variables los gráficos de *simples slopes*, presentan rectas que no son paralelas y que potencialmente se cruzan.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 4: interacción negativa"

#---------------------------------------------------------------
# simple slope
#---------------------------------------------------------------

#--------------------------------------
# fitted model
#--------------------------------------

m04 <- lm(y ~ 1 + x + w + x*w, data = data_example_4)

#--------------------------------------
# plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_4 <- interactions::interact_plot(m04, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Escenario 4',
subtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = -100'
)

plot_4


```

Finalmente, en el **escenario 5** incluimos un efecto de interacción. En este caso, es una interacción positiva que se espera que aumente las brechas observadas entre $y_{i}$ y $x_{i}$, condicional a los valores de $w_{i}$. 

En términos sustantivos, los resultados de este escenario nos indican que la brecha en los puntajes de matemáticas relativa a la escolaridad de los padres, es de mayor tamaño entre los estudiantes que asisten a escuelas privadas, en contraste a los estudiantes que asisten a escuelas públicas.

Los gráficos de *simple slope*, para este tipo de escenarios muestran rectas que se cruzan, y que se *abren* a medida que aumentan los valores de $x_{i}$.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true
#| fig-cap: "Escenario 1: figura sin efectos"

#---------------------------------------------------------------
# simple slope
#---------------------------------------------------------------

#--------------------------------------
# fitted model
#--------------------------------------

m05 <- lm(y ~ 1 + x + w + x*w, data = data_example_5)

#--------------------------------------
# plot
#--------------------------------------

library(ggplot2)
library(hrbrthemes)
plot_5 <- interactions::interact_plot(m05, 
pred = x, 
modx = w,
interval = TRUE,
y.label = 'Matemáticas',
x.label = 
'Educación de los padres
(No Terciaria = 0,Terciaria = 1)
',
modx.labels = c('Pública','Privada'),
colors = c('black','red')
) +
scale_y_continuous(
  breaks = seq(400, 1000, by = 100),
  limits = c(400, 1000)
) +
theme_ipsum() +
labs(
title = 'Escenario 5',
subtitle = 'b0 = 700, b1 = 100, b2 = 100, b3 = 100'
)

plot_5


```

## Estimados de regresión

A continuación vamos a ajustar modelos de regresión sobre los datos generados empleados en los escenarios 1 a 5. Como los datos sobre los que ajustaremos los modelos son datos simulados, de una sola realización del modelo definido o mecanismos generador datos, los resultados obtenidos van a ser muy parecidos a los parámetros definidos; pero no exactamente iguales.

Esta diferencia entre el **parámetro** del modelo y el **estimado** del modelo suele simbolizarse mediante acentos en la notación. Por ejemplo el parámetro que expresa a la relación entre $y_{i}$ e $x_{i}$ es $\beta_{1}$, mientras que el estimado de esta relación es $\hat{\beta}_{1}$.

El siguiente ejercicio nos servirá para ilustrar como serían los modelos de regresión que se pueden ajustar sobre los datos que generan a las figuras de los 5 escenarios anteriores.


```{r, echo = TRUE, eval = TRUE, warning=FALSE}
#| code-fold: true

#---------------------------------------------------------------
# regression
#---------------------------------------------------------------

#--------------------------------------
# fit models
#--------------------------------------

m01 <- lm(y ~ 1 + x + w + x*w, data = data_example_1)
m02 <- lm(y ~ 1 + x + w + x*w, data = data_example_2)
m03 <- lm(y ~ 1 + x + w + x*w, data = data_example_3)
m04 <- lm(y ~ 1 + x + w + x*w, data = data_example_4)
m05 <- lm(y ~ 1 + x + w + x*w, data = data_example_5)

#--------------------------------------
# estimates
#--------------------------------------

texreg::screenreg(list(m01, m02, m03, m04, m05), 
  star.symbol = "*", 
  center = TRUE, 
  doctype = FALSE,
  dcolumn = TRUE, 
  booktabs = TRUE,
  single.row = FALSE,
  custom.model.names = c('E1','E2','E3','E4','E5'))

```

## Medias esperadas empleando a los resultados del modelo de regresión

La idea general es que con la ecuación de regresión anterior podemos producir valores. Podemos tanto producir valores esperados, como las medias esperadas de los grupos, como los valores esperados por el modelo. Nos vamos a enfocar en las medias esperadas de cada grupo. Ordenando los diferentes términos de la regresión general con interacción podemos obtener las medias esperadas de cada uno de los grupos implicados por ambos factores.

- Media de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas públicas

$$E(\bar{y} | x_{i} = 0, w_{i} = 0) = \beta_{0} + \beta_{1}*0 + \beta_{2}*0 + \beta_{3}*0*0$$

- Media de estudiantes con padres de escolaridad menor a terciaria, que asisten a escuelas privadas

$$E(\bar{y} | x_{i} = 0, w_{i} = 1) = \beta_{0} + \beta_{1}*0 + \beta_{2}*1 + \beta_{3}*0*1$$

- Media de estudiantes con padres de escolaridad terciaria, que asisten a escuelas públicas

$$E(\bar{y} | x_{i} = 1, w_{i} = 0) = \beta_{0} + \beta_{1}*1 + \beta_{2}*0 + \beta_{3}*1*0$$

- Media de estudiantes con padres de escolaridad terciaria, que asisten a escuelas privadas

$$E(\bar{y} | x_{i} = 1, w_{i} = 1) = \beta_{0} + \beta_{1}*1 + \beta_{2}*1 + \beta_{3}*1*1$$




# Ejemplo sustantivo



## Terminologia

- Efectos principales (i.e., *main effects*)

- Efectos de interacción (i.e., *interaction term*)

## Forma de las interacciones



# Caso aplicado

## Introducción

## Datos

## Preparar Datos

## Ajustar Modelo

## Tabla de resultados

## Descripción de resultados

# Tópicos en estudios de interacción

## Interacciones entre dicotómicas

## Interacciones entre dicotómicas y continuas

## Interacciones entre continuas

## Inferencia en interacciones

## Poder estadístico

## Modelos alternativos para evaluar interacciones

## Interacciones en modelos generalizados

# Referencias

Rabe-Hesketh, S., & Skrondal, A. (2012). Multilevel and Longitudinal Modeling Using Stata, Volumes I and II, Third Edition (3rd ed.). Stata Press.

LeBeau, B. (2024). simglm: Simulate Models Based on the Generalized Linear Model. R package version 0.9.20, https://github.com/lebebr01/simglm.

Bauer, D. J., & Curran, P. J. (2005). Probing Interactions in Fixed and Multilevel Regression: Inferential and Graphical Techniques. Multivariate Behavioral Research, 40(3), 373–400. https://doi.org/10.1207/s15327906mbr4003_5


Preacher, K. J., Curran, P. J., & Bauer, D. J. (2006). Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis. Journal of Educational and Behavioral Statistics, 31(3), 437–448. https://doi.org/10.3102/10769986031004437


# Bibliografía anotada

Jaccard, J., Wan, C. K., & Turrisi, R. (1990). The Detection and Interpretation of Interaction Effects Between Continuous Variables in Multiple Regression. Multivariate Behavioral Research, 25(October), 467–478. https://doi.org/10.1207/s15327906mbr2504

Maslowsky, J., Jager, J., & Hemken, D. (2015). Estimating and interpreting latent variable interactions: A tutorial for applying the latent moderated structural equations method. International Journal of Behavioral Development, 39(1), 87–96. https://doi.org/10.1177/0165025414552301

Preacher, K. J., Curran, P. J., & Bauer, D. J. (2006). Computational Tools for Probing Interactions in Multiple Linear Regression, Multilevel Modeling, and Latent Curve Analysis. Journal of Educational and Behavioral Statistics, 31(3), 437–448. https://doi.org/10.3102/10769986031004437

Aguinis, H., & Gottfredson, R. K. (2010). Best-practice recommendations for estimating interaction effects using moderated multiple regression. Journal of Organizational Behavior, 31(6), 776–786. https://doi.org/10.1002/job.686

Mize, T. D. (2019). Best practices for estimating, interpreting, and presenting nonlinear interaction effects. Sociological Science, 6, 81–117. https://doi.org/10.15195/V6.A4

Curran, P. J., Bauer, D. J., & Willoughby, M. T. (2004). Testing main effects and interactions in latent curve analysis. Psychological Methods, 9(2), 220–237. https://doi.org/10.1037/1082-989X.9.2.220

Sun, R., & Willson, V. L. (2009). Evaluating intercept-slope interactions in latent growth modeling. Structural Equation Modeling, 16(2), 226–244. https://doi.org/10.1080/10705510902751051

Baranger, D. A. A., Finsaas, M. C., Goldstein, B. L., Vize, C. E., Lynam, D. R., & Olino, T. M. (2023). Tutorial: Power Analyses for Interaction Effects in Cross-Sectional Regressions. Advances in Methods and Practices in Psychological Science, 6(3). https://doi.org/10.1177/25152459231187531

Bauer, D. J., & Curran, P. J. (2005). Probing Interactions in Fixed and Multilevel Regression: Inferential and Graphical Techniques. Multivariate Behavioral Research, 40(3), 373–400. https://doi.org/10.1207/s15327906mbr4003\_5

León, O. G., & Montero, I. (2001). Cómo explicar el concepto de interacción sin estadística: Análisis gráfico de todos los casos posibles en un diseño 2 x 2. Psicothema, 13(1), 159–165.



# Code exploratory

```{r, echo = FALSE, eval = TRUE, include = FALSE}

#---------------------------------------------------------------
# exploratory
#---------------------------------------------------------------

#--------------------------------------
# codebook
#--------------------------------------

library(dplyr)
erce::erce_2019_qa6 %>%
labelled::lookfor() %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble() %>%
knitr::kable()

#--------------------------------------
# selected variables
#--------------------------------------
library(dplyr)
erce::erce_2019_qa6 %>%
labelled::lookfor() %>%
labelled::lookfor_to_long_format() %>%
tibble::as_tibble() %>%
dplyr::filter(variable %in% c('MAT_1','EDU', 'DEP')) %>%
dplyr::select(pos, variable, label, levels, value_labels) %>%
knitr::kable()

#--------------------------------------
# load data
#--------------------------------------

library(dplyr)
data_a6 <- erce::erce_2019_qa6 %>%
           erce::remove_labels()

#--------------------------------------
# countries with three and two systems
#--------------------------------------

data_a6 %>%
dplyr::count(COUNTRY, DEP) %>%
knitr::kable()

#--------------------------------------
# example with Colombia
#--------------------------------------

data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(id_k = 1) %>%
mutate(id_j = IDSCHOOL) %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
lm(y ~ 1 + x*w, data = .) %>%
summary()


data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(id_k = 1) %>%
mutate(id_j = IDSCHOOL) %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
r4sda::center_variables(data = ., variable = x , name = x) %>%
r4sda::center_variables(data = ., variable = w , name = w) %>%
lmerTest::lmer(y ~ 1 + x_w*w_b + x_b*w_b + (1 + x_w | id_j), data = ., REML = FALSE) %>%
summary()


data_model <- data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(id_k = 1) %>%
mutate(id_j = IDSCHOOL) %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
r4sda::center_variables(data = ., variable = x , name = x) %>%
r4sda::center_variables(data = ., variable = w , name = w)

f00 <- as.formula('y ~ 1 + x_w + (1 | id_j)')
f01 <- as.formula('y ~ 1 + x_w + (1 + x_w | id_j)')
f02 <- as.formula('y ~ 1 + x_w + x_b + w_b + (1 | id_j)')
f03 <- as.formula('y ~ 1 + x_w + x_b + w_b + x_w:w_b + x_b:w_b + (1 + x_w | id_j)')

# ----------------------------------------------- 
# fit models
# -----------------------------------------------

m00 <- lme4::lmer(f00, data = data_model, REML = FALSE)
m01 <- lme4::lmer(f01, data = data_model, REML = FALSE)
m02 <- lme4::lmer(f02, data = data_model, REML = FALSE)
m03 <- lme4::lmer(f03, data = data_model, REML = FALSE)


texreg::screenreg(list(m00, m01, m02, m03), 
  star.symbol = "*", 
  center = TRUE, 
  doctype = FALSE,
  dcolumn = TRUE, 
  booktabs = TRUE,
  single.row = FALSE)


# ----------------------------------------------- 
# lrt mixture
# -----------------------------------------------

specify_decimal <- function(x, k) format(round(x, k), nsmall=k)

lrt_mixture <- function(model_0, model_1){

lrt    <- as.numeric(
          lmtest::lrtest(model_0,model_1)$Chisq[2])

pval   <- .5*pchisq(lrt, df=1, lower.tail=FALSE) + 
          .5*pchisq(lrt, df=2, lower.tail=FALSE)

result <- paste0("LRT_mixture = ",
          specify_decimal(lrt,2),
          ", pval = ",
          specify_decimal(pval,2))

return(result)
}

# ----------------------------------------------- 
# lrt mixture results
# -----------------------------------------------

lrt_mixture(m00, m01)



#--------------------------------------
# number of observations
#--------------------------------------

data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
nrow()

#--------------------------------------
# number of observations
#--------------------------------------

data_model <- data_a6 %>%
dplyr::filter(COUNTRY == 'COL') %>%
mutate(y = MAT_1) %>%
mutate(x = EDU) %>%
mutate(w = case_when(
DEP == 1 ~ 0, # public
DEP == 2 ~ 1, # private
DEP == 3 ~ 0  # other
)) %>%
mutate(xw = x*w)

lavaan_model <- '
y ~ b0*1
y ~ b1*x
y ~ b2*w
y ~ b3*xw

# expected means
m0 := b0 + b1*0 + b2*0 + b3*(0*0)
m1 := b0 + b1*0 + b2*1 + b3*(0*1)
m2 := b0 + b1*1 + b2*0 + b3*(1*0)
m3 := b0 + b1*1 + b2*1 + b3*(1*1)
'


# -----------------------------------------------
# fit model
# -----------------------------------------------

m01 <- lavaan::sem(lavaan_model, 
       mimic = 'MPLUS',
       data = data_model)

# -----------------------------------------------
# display summary
# -----------------------------------------------

lavaan::summary(m01, 
  fit.measures=TRUE,
  standardized=TRUE,
  rsquare=TRUE)


```







# Anexos

## Texto sin editar

Diagrama Conceptual

Diagrama de vías








**Descriptivamente**, podemos calcular las medias de ambos grupos de estudiantes, y ademas, podríamos calcular la diferencia de medias entre ambos grupos, y con lo anterior tener una noción de si los estudiantes difieren en sus puntajes *condicional a* la escolaridad de sus padres.

Ahora, podemos abordar la misma inquietud empleando un modelo de regresión:

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}$$

Donde,

- $y_{i}$ = puntaje total de cada estudiante $_{i}$.

- $x_{i}$ = escolaridad máxima de los padres de cada estudiante $_{i}$.

Con los resultados de un modelo de regresión como el anterior podemos obtener las medias esperadas de cada grupo:

- Media de estudiantes con padres de escolaridad menor a terciaria

$$\beta_{0} + \beta_{1}(x_{i} = 0)$$

- Media de estudiantes con padres de escolaridad terciaria

$$\beta_{0} + \beta_{1}(x_{i} = 1)$$

**¿Que pasaría sin incluimos una tercera variable?** Si tuvieramos la información de una tercera variable, dado que estamos pensando el modelo de regresión como una forma de expresar medias condicionadas, es que entonces podriamos tener otra diferencia adicional entre grupos. Pensemos en una tercera covariable como la dependencia de la escuelas (e.g., Privadas y Públicas). Para efectos del ejemplo, pensemos que las escuelas privadas toman un valor uno, y las escuelas públicas toman un valor cero.

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \epsilon_{i}$$

- $w_{i}$ = tipo de escuela a la que asisten a los estudiantes $_{i}$, donde 1 son escuelas privadas, y 0 son escuelas públicas.

Con el modelo anterior, solo podemos representar (i.e., asumir) que las medias entre los grupos aumentan o disminuyen con respecto a al intercepto ( $\beta_{0}$ ), condicional a los valores de $x_{i}$ (i.e. la escolaridad máxima de los padres) y condicional a los valores de $w_{i}$ (i.e., la dependencia administrativa de la escuelas).

Para poder representar que las medias anteriores son condicionales entre sí o que **interactúan**, necesitamos incluir un término adicional: el múltiplo de las variables $x_{i}$ e $w_{i}$, es decir $x_{i}*w_{i}$. Este término nos permitirá obtener un coeficiente de regresión adicional, el cual nos permite saber si hay un "exceso" en las diferencias de medias que estamos obteniendo con los coeficientes anteriores. Este "exceso" puede ser positivo o negativo. 

Si incluimos a todos los términos, ahora contamos con un modelo de regresión, el cual incluye a un **término de interacción** para las variabels $x_{i}$ e $w_{i}$.

$$y_{i} = \beta_{0} + \beta_{1}x_{i} + \beta_{2}w_{i} + \beta_{3}(x_{i}*w_{i})+\epsilon_{i}$$


La inquietud general que uno busca responder con los modelos de regresión con interacciones consiste en evaluar si la relación entre dos variables es equivalente, cuando consideramos la información de una **tercera variable**.


